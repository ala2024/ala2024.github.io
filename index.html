<!DOCTYPE HTML>
<!--
Read Only by HTML5 UP
html5up.net | @ajlkn
Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->

<html>
    <head>
        <title>ALA 2024</title>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
        <meta name="google-site-verification" content="aK65vKjdK-pwXkpxs-JBibUAgOiIT_3Kq3S66UUr1N8" />
        <link rel="stylesheet" href="assets/css/main.css" />
        <link rel="icon" type="image/png" href="images/icons/robot.png"/>
        <!-- Global site tag (gtag.js) - Google Analytics -->
        <script async src="https://www.googletagmanager.com/gtag/js?id=G-3WQZBEV8XB"></script>
        <script>
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());

          gtag('config', 'G-3WQZBEV8XB');
        </script>
        
    </head>
    <body class="is-preload">
        
        <!-- Header -->
        <section id="header">
            <header>
                <!--<span class="image avatar"><img src="images/avatar.jpg" alt="" /></span>-->
                <h1 id="logo"><a href="#">ALA 2024</a></h1>
                <p style="color:#FFF2D2">Adaptive and Learning Agents Workshop<br />
                at AAMAS, Auckland, NZ</p>
            </header>
            <nav id="nav">
                <ul>
                    <li><a href="#news" class="active">News</a></li>
                    <li><a href="#about">About</a></li>
                    <li><a href="#dates">Important Dates</a></li>
                    <li><a href="#submission">Submission Details</a></li>
                    <!--<li><a href="#challenge">ALA-Cogment Challenge</a></li>-->
                    <li><a href="#journal">Journal Special Issue</a></li>
                    <!--<li><a href="#program">Program</a></li>-->
                    <!--<li><a href="#posters">Poster Sessions</a></li>-->
                    <li><a href="#accepted">Accepted Papers</a></li>
                    <!--<li><a href="#talks">Invited Talks</a></li>-->
                    <!--<li><a href="#awards">Awards</a></li>-->
                    <!--<li><a href="#pc">Program Committee</a></li>-->
                    <li><a href="#organization">Organization</a></li>
                    <!--<li><a href="#sponsor">Sponsorship</a></li>-->
                    <!--<li><a href="#ai_ethics">AI & Ethics</a></li>-->
                    <li><a href="#contact">Contact</a></li>
                    
                </ul>
            </nav>
            <footer>
                <ul class="icons">
                    <li><a href="https://www.linkedin.com/groups/4412140/" class="icon fa-linkedin"><span class="label">Linkedin</span></a></li>
                    <li><a href="mailto:ala.workshop.2024@gmail.com" class="icon fa-envelope"><span class="label">Email</span></a></li>
                </ul>
            </footer>
        </section>
        
        <!-- Wrapper -->
        <div id="wrapper">
            
            <!-- Main -->
            <!-- News -->
            <section id="news">
                <div id="main">
                    <div class="image main" data-position="center">
                        <img src="images/2560px-Auckland_Skyline_as_seen_from_Devonport_20100128_3.jpg" alt=""/>
                        <h2 id="banner-header" style="color:#FFF2D2">ALA 2024</h2>
                        <h3 id="banner-description" style="color:#FFF2D2">6 &amp; 7 May 2024, Auckland, NZ</h3>
                    </div>
                    <div class="container">
                        <h3>News</h3>
                        <ul>
<!--
                            <li> 08 May 2022: We invite all authors and participants to join our <a href="https://join.slack.com/t/ala2022/shared_invite/zt-18b830rie-9DBK_5AMQ__kqrrXX5cnqg" target="_blank">Slack workspace</a>! Check out the <a href="#program">program</a> for more details.</li>
                            <li> 08 May 2022: All video presentations have been uploaded to the <a href="https://www.youtube.com/channel/UCbmHKFUVThoAweXhRxtAm_Q/playlists" target="_blank">ALA YouTube channel</a>!.</li>
-->
<!--

                            <li>24 June: Best paper is announced in the <a href="#awards"><em>awards</em></a>.</li>
                            <li>8 May 2023: Camera-ready copies of all papers are viewable in the <a href="#program"><em>program</em></a>.</li>
                            <li>4 May 2023: Stay tuned for the camera-ready PDF's of each paper, which will be available on the website shortly.</li>
                            <li>3 May 2023: The <a href="#program"><em>program</em></a> for the workshop is now available. </li>
                            <li>3 May 2023: We are excited to announce Shimon Whiteson as a keynote speaker for ALA 2023. </li>
                            <li>25 April 2023: We are excited to announce Peter Stone as a keynote speaker for ALA 2023. </li>
                            <li>21 April 2023: We are excited to announce Christopher Amato as a keynote speaker for ALA 2023. </li>
                            
                            <li>17 April 2023: Information regarding the Neural Computing & Applications Journal Special Issue and Best Paper Award are now posted.</li>
                            <li>31 March 2023: The list of <a href="#accepted">accepted papers</a> is now online.</li>
                            <li>24 March 2023: Stay tuned! ALA 2023 acceptances will be announced on March 27th.</a></li>
                            <li>24 Jan 2023: ALA 2023 submission deadline has been extended to 24 Feb 2023 23:59 UTC </a></li>
                            <li>22 Dec 2022: ALA 2023 Submission Link can be found <a href="https://easychair.org/my/conference?conf=ala2023" target="_blank">here</a></li>
                            <li>22 Dec 2022: ALA Call for Papers can be found <a href="https://easychair.org/my/conference?conf=ala2023" target="_blank">here</a></li>
                        -->
                            <li>21 Mar 2024: The deadline for the camera-ready version of accepted papers has been extended to 19 Apr 2024</a></li>
                            <li>1 Mar 2024: The final decisions for ALA 2024 will be slightly delayed. Due to the overall lower number of submissions this year, the Workshop on Reinforcement Learning in Games will be merged into ALA and unifying the review process will take a few more days. Thanks for your patience!</a></li>
                            <li>9 Feb 2024: ALA 2024 submission deadline has been further extended to 12 Feb 2024 23:59 UTC </a></li>
                            <li>29 Jan 2024: ALA 2024 submission deadline has been extended to 9 Feb 2024 23:59 UTC </a></li>
                            <li>4 Dec 2023: ALA 2024 Website goes live!</li>
                        </ul>
                    </div>
                    </section>
            <!-- One -->
            <section id="about">
                <div class="container">
                    <header class="major">
                        <h3>ALA 2024 - Workshop at <a href="https://www.aamas2024-conference.auckland.ac.nz/" target="_blank">AAMAS 2024</a></h3>
                        <p align="justify">Adaptive and Learning Agents (ALA) encompasses diverse fields such as Computer Science, Software Engineering, Biology, as well as
                        Cognitive and Social Sciences. The ALA workshop will focus on agents and multiagent systems which employ learning or adaptation.</p>
                    </header>
                    <p align="justify">This workshop is a continuation of the long running AAMAS series of workshops on adaptive agents, now in its sixteenth year. Previous editions of this workshop may be found at the following urls:</p>
                    <ul>
                        <li><a href="https://alaworkshop2023.github.io/" target="_blank">ALA-23</a></li>
                        <li><a href="https://ala2022.github.io/" target="_blank">ALA-22</a></li>
                        <li><a href="http://ala2021.vub.ac.be" target="_blank">ALA-21</a></li>
                        <li><a href="http://ala2020.vub.ac.be" target="_blank">ALA-20</a></li>
                        <li><a href="http://ala2019.vub.ac.be" target="_blank">ALA-19</a></li>
                        <li><a href="http://ala2018.it.nuigalway.ie" target="_blank">ALA-18</a></li>
                        <li><a href="http://ala2017.it.nuigalway.ie/" target="_blank">ALA-17</a></li>
                        <li><a href="http://ala2016.csc.liv.ac.uk/" target="_blank">ALA-16</a></li>
                        <li><a href="http://ala2015.csc.liv.ac.uk/" target="_blank">ALA-15</a></li>
                        <li><a href="http://swarmlab.unimaas.nl/ala2014/" target="_blank">ALA-14</a></li>
                        <li><a href="http://swarmlab.unimaas.nl/ala2013/" target="_blank">ALA-13</a></li>
                        <li><a href="http://ai.vub.ac.be/ALA2012/" target="_blank">ALA-12</a></li>
                        <li><a href="http://como.vub.ac.be/ALA2011/" target="_blank">ALA-11</a></li>
                        <li><a href="http://www-users.cs.york.ac.uk/%7Ekudenko/ala10/" target="_blank">ALA-10</a></li>
                        <li><a href="http://teamcore.usc.edu/taylorm/ALA09/" target="_blank">ALA-09</a></li>
                        <li><a href="http://ki.informatik.uni-wuerzburg.de/%7Ekluegl/ALAMAS.ALAg/" target="_blank">ALAMAS+ALAg-08</a></li>
                        <li><a href="http://web.engr.oregonstate.edu/%7Ektumer/conferences/alag07.html" target="_blank">ALAg-07</a></li>
                        <!--  <li><a href="http://www.cs.unimaas.nl/alamas/">ALAMAS-07</a></li> -->
                        <li><a href="http://www-users.cs.york.ac.uk/%7Ekazakov/aamas/">Earlier editions</a> </li>
                    </ul>
                    <p align="justify">The goal of this workshop is to increase awareness of and interest in adaptive agent research, encourage collaboration and give a representative overview of current research in the area of adaptive and learning agents and multi-agent systems. It aims at bringing together not only scientists from different areas of computer science (e.g. agent architectures, reinforcement learning, evolutionary algorithms) but also from different fields studying similar concepts (e.g. game theory, bio-inspired control, mechanism design).</p>
                    
                    <p align="justify">The workshop will serve as an inclusive forum for the discussion of ongoing or completed work covering both theoretical and practical aspects of adaptive and learning agents and multi-agent systems.</p>
                    
                    <p align="justify">This workshop will focus on all aspects of adaptive and learning agents and multi-agent systems with a particular amphasis on how to modify established learning techniques and/or create new learning paradigms to address the many challenges presented by complex real-world problems. The topics of interest include but are not limited to:</p>
                    
                    <ul>
                        <li>Novel combinations of reinforcement and supervised learning approaches</li>
                        <li>Integrated learning approaches using reasoning modules like negotiation, trust, coordination, etc..</li>
                        <li>Supervised and semi-supervised multi-agent learning</li>
                        <li>Reinforcement learning (single- and multi-agent)</li>
                        <li>Novel deep learning approaches for adaptive single- and multi-agent systems</li>
                        <li>Multi-objective optimisation in single- and multi-agent systems</li>
                        <li>Planning (single- and multi-agent)</li>
                        <li>Reasoning (single- and multi-agent)</li>
                        <li>Distributed learning</li>
                        <li>Adaptation and learning in dynamic environments</li>
                        <li>Evolution of agents in complex environments</li>
                        <li>Co-evolution of agents in a multi-agent setting</li>
                        <li>Cooperative exploration and learning to cooperate and collaborate</li>
                        <li>Learning trust and reputation</li>
                        <li>Communication restrictions and their impact on multi-agent coordination</li>
                        <li>Design of reward structure and fitness measures for coordination</li>
                        <li>Scaling learning techniques to large systems of learning and adaptive agents</li>
                        <li>Emergent behaviour in adaptive multi-agent systems</li>
                        <li>Game theoretical analysis of adaptive multi-agent systems</li>
                        <li>Neuro-control in multi-agent systems</li>
                        <li>Bio-inspired multi-agent systems</li>
                        <li>Human-in-the-loop learning systems</li>
                        <li>Applications of adaptive and learning agents and multi-agent systems to real world complex systems</li>
                    </ul>
                    
                    <p align="justify">Extended and revised versions of papers presented at the workshop will be eligible for inclusion in a journal special issue (see below).</p>
                    <p class="entry-footer"></p>
                </div>
            </section>
            
            <!-- Two -->
            <section id="dates">
                <div class="container">
                    <h3>Important Dates</h3>
                    
                    <ul class="feature-icons">
                        
                        <li class="fa-telegram">Submission Deadline:<s> 5 February 2024 9 February 2024 </s>
                            &nbsp;&nbsp;<font color="#4872A6"><b>12 February 2024</b></font></li>
                        <li class="fa-bell">Notification of acceptance: <font color="#4872A6"><b>4 March  2024</b></font>
                        <li class="fa-file-pdf-o">Camera-ready copies: <s> 25 March 2024 </s>
                            &nbsp;&nbsp;<font color="#4872A6"><b>19 April 2024</b></font></li>
                        <li class="fa-users">Workshop:            <b>6 - 7 May 2024</b></li>
                    
                    </ul>
                </div>
            </section>
            
            <!-- Three -->
                <section id="submission">
                    <div class="container">
                        <h3>Submission Details</h3>
                        <p align="justify">Papers can be submitted through <a href="https://openreview.net/group?id=AAMAS/2024/Workshop/ALA" alt="" target="_blank">OpenReview</a>.</p>
                        <p align="justify">We invite submission of original work, up to 8 pages in length (excluding references) in the ACM proceedings format (i.e. following the AAMAS formatting instructions). This includes work that has been accepted as a poster/extended abstract at AAMAS 2024. Keeping with previous ALA guidelines, papers are limited to 8 pages plus references. Additionally, we welcome submission of preliminary results, i.e. work-in-progress, as well as visionary outlook papers that lay out directions for future research in a specific area, both up to 6 pages in length, although shorter papers are very much welcome, and will not be judged differently. Finally, we also accept recently published journal papers in the form of a 2 page abstract.</p>
                        <p align="justify">Furthermore, <strong> for submissions that were rejected or accepted as extended abstracts at AAMAS</strong>, authors need to also append the received reviews and a pdfdiff.</p>
                        <p align="justify">All submissions will be peer-reviewed (doubl-blind). Accepted work will be allocated time for poster and possibly oral presentation during the workshop. In line with AAMAS, the workshop will be <strong>fully offline</strong>. Extended versions of original papers presented at the workshop will also be eligible for inclusion in a post-proceedings journal special issue.  </p>
                        
                        <p align="justify">When preparing your submission for ALA 2024, please be sure to remove the AAMAS copyright block, citation information and running headers. You leave the submission id in the AAMAS template empty as we use OpenReview instead of easy chair. Please replace the AAMAS copyright block in the main.tex file from the AAMAS template with the following:
                            <pre>
                                \setcopyright{none}
                                \acmConference[ALA '24]{Proc.\@ of the Adaptive and Learning Agents Workshop (ALA 2024)}
                                {May 6-7, 2024}{Online, \url{https://ala2024.github.io/}}{Avalos, Milec, M\"uller, Wang, Yates (eds.)}
                                \copyrightyear{2024}
                                \acmYear{2024}
                                \acmDOI{}
                                \acmPrice{}
                                \acmISBN{}
                                \settopmatter{printacmref=false}
                            </pre>
                        </p>
                        <p align="justify">For the submission of the camera-ready paper make sure to submit the deanonymized version with the replaced copyright block above.</p>
                </div>
            </section>

            <!-- Three -->
            <!--
            <section id="challenge">
                <div class="container">
                    <h3>ALA-Cogment Challenge</h3>
                    <p align="justify">All accepted ALA papers will be eligable to take part in the <a href="https://ai-r.com/aamas-2022-welcome-to-the-ala-cogment-challenge/" alt="" target="_blank">ALA-Cogment Challenge</a>. The ALA-Cogment Challenge offers a total prize pool of $10,000. </p>

                    <p align="justify">Cogment is an open-source framework for distributed multi-actor training, deployment, and operations. To take part in the competition you must submit a paper to ALA by 11-Feb-2022. Then all accepted ALA particiapants must, by April 30, 2022:

                        <ul>
                        <li> Sign up for the <a href="https://eyrwknioxo8.typeform.com/to/j4jMvQxp" alt="" target="_blank">ALA-Cogment Challenge.</a></li>
                        <li>Cite Cogment in your paper.</li>
                        <li>Implement an experimental setup using Cogment for your submitted paper and share it with the ALA-Cogment Challenge evaluation team (e.g. in a GitHub repo or in a zip file). We strongly encourage authors to publish their code to meet this requirement.</li>
                        </ul>


                    </p>


                    <p align="justify">We will award up to three grand prizes to ALA-Cogment Challenge submissions that make the best use of Cogment for applications or for fundamental research. Grand prizes will be awarded according to criteria that include (but are not limited to):

                        <ul>
                        <li>The richness of the submission’s Cogment usage with respect to agents, implementations, environments, benchmarking, and evaluations.</li>
                        <li>The creative involvement of human actors or evaluators during the submission’s Cogment training or validation process. </li>
                        <li>The complexity of the AI problem being addressed with Cogment.</li>
                        </ul>

                    We will announce the grand prize results live during the May 9-10, 2022 workshop. Further details about the competition can be found here: <a href="https://ai-r.com/aamas-2022-welcome-to-the-ala-cogment-challenge/" alt="" target="_blank">https://ai-r.com/aamas-2022-welcome-to-the-ala-cogment-challenge/</a>
                    </p>


                    
                </div>
            </section>
            -->
            
            <!-- Four -->
            <section id="journal">
                <div class="container">
                    <h3>Journal Special Issue</h3>
                    
                    <p align="justify">We are delighted to announce that extended versions of all original contributions at ALA 2024 will be eligible for inclusion in a special issue of the Springer journal <a href="https://www.springer.com/computer/ai/journal/521" alt="https://www.springer.com/computer/ai/journal/521" target="_blank">Neural Computing and Applications</a> (Impact Factor 6.0). The deadline for submitting extended papers will be 15 November 2024.</p>
                    <a href="https://www.springer.com/computer/ai/journal/521" target='_blank'><img src='images/nca.jpg' height='200px' alt='NCA' /></a>
                    
                    <p align="justify">For further information please contact the workshop organizers and Patrick Mannion.</p>
                    <p class="entry-footer"></p>
                    
                </div>
            </section>
            
            <!-- Five -->
            <!--
            <section id="program">
                <div class="container">
                    <h3>Program</h3>
                    <p>All times are presented in local London time.</p>
                    <h4>Monday May 29</h4>
                    <table width="100%" >
                    <tr>
                        <td></td>
                        <td><b>Welcome &amp; Opening Remarks</b>
                    </tr>
                    <tr>
                        <td>08:30-10:00</td>
                        <td><b>Session I - Chair: Fernando P. Santos</b></td>
                        <tr>
                            <td>08:30-09:30</td>
                            <td>Invited Talk: Shimon Whiteson (Oxford)<br/><em><a href="#talks1">Efficient & Realistic Simulation for Autonomous Driving</a></em></td>
                    </tr>
                    <tr>
                        <td>09:30-09:45</td>
                        <td>Long Talk: Raphael Avalos, Florent Delgrange, Ann Nowe, Guillermo A. Pérez and Diederik M. Roijers<br><a href="papers/ALA2023_paper_52.pdf"><em>The Wasserstein Believer: Learning Belief Updates for Partially Observable Environments through Reliable Latent Space Models</em></a></td>
                    </tr>
                    <tr>
                        <td>09:45-10:00</td>
                        <td>Long Talk: Felipe Leno Da Silva, Jiachen Yang, Mikel Landajuela, Andre Goncalves, Alexander Ladd, Daniel Faissol and Brenden Petersen<br><a href="papers/ALA2023_paper_3.pdf"><em>Toward Multi-Fidelity Reinforcement Learning for Symbolic Optimization</em></a></td>
                    </tr>
                    <tr>
                        <td>10:00-11:00</td>
                        <td><b>Coffee Break</b><br/></td>
                    </tr>
                    <tr><td>11:00-12:30</td><td><b>Session II - Chair: Patrick Mannion</b></tr>
                    <tr>
                        <td>11:00-11:15</td>
                        <td>Long Talk: Minae Kwon, John Agapiou, Edgar Duéñez-Guzmán, Romuald Elie, Georgios Piliouras, Kalesha Bullard and Ian Gemp<br><a href="papers/ALA2023_paper_17.pdf"><em>Aligning Local Multiagent Incentives with Global Objectives</em></a></td>
                        <tr>
                            <td>11:15-11:30</td>
                            <td>Matthew E. Taylor<br><a href="papers/ALA2023_paper_29.pdf"><em>Reinforcement Learning Requires Human-in-the-Loop Framing and Approaches</a></br></td>
                            </tr>
                    <tr>
                        <td>11:30-12:30</td>
                        <td><b>Short Talks, 6 minutes each in order:</b>
                            <ul>
                                <li>Qian Shao, Pradeep Varakantham and Shih-Fen Cheng<br><a href="papers/ALA2023_paper_12.pdf"><em>Cost Constrained Imitation Learning</em></a></li>
                                <li>Lin Shi and Bei Peng<br><a href="papers/ALA2023_paper_2.pdf"><em>Curriculum Learning for Relative Overgeneralization</em></a></li>
                                <li>Nicola Mc Donnell, Enda Howley and Jim Duggan<br><a href="papers/ALA2023_paper_41.pdf"><em>QD(λ) Learning: Towards Multi-agent Reinforcement Learning for Learning Communication Protocols</em></a></li>
                                <li>David Radke and Kyle Tilbury<br><a href="papers/ALA2023_paper_63.pdf"><em>Learning to Learn Group Alignment: A Self-Tuning Credo Framework with Multiagent Teams</em></a></li>
                                <li>Kartik Bharadwaj, Chandrashekar Lakshminarayanan and Balaraman Ravindran<br><a href="papers/ALA2023_paper_54.pdf"><em>Continuous Tactical Optimism and Pessimism</em></a></li>
                                <li>Nicole Orzan, Erman Acar, Davide Grossi and Roxana Rădulescu<br><a href="papers/ALA2023_paper_27.pdf"><em>Emergent Cooperation and Deception in Public Good Games</em></a></li>
                                <li>Isuri Perera, Frits de Nijs and Julian Garcia<br><a href="papers/ALA2023_paper_32.pdf"><em>Learning to cooperate against ensembles of diverse opponents</em></a></li>
                                <li>Changxi Zhu, Mehdi Dastani and Shihan Wang<br><a href="papers/ALA2023_paper_44.pdf"><em>Continuous Communication with Factorized Policy Gradients in Multi-agent Deep Reinforcement Learning</em></a></li>
                                <li>Johan Källström and Fredrik Heintz<br><a href="papers/ALA2023_paper_50.pdf"><em>Model-Based Multi-Objective Reinforcement Learning with Dynamic Utility Functions</em></a></li>
                            </ul>
                        </td>
                    </tr>
                    <tr>
                        <td>12:30-14:00</td>
                        <td><b>Lunch Break</b><br/></td>
                    </tr>
                    <tr><td>14:00-15:45</td><td><b>Short Talks & Poster Session - Chair: Gaurav Dixit</b></td></tr>
                    <tr>
                        <td>14:00-14:15</td>
                        <td><b>Short Talks, 6 minutes each in order:</b>
                            <ul>
                                <li>Short Talk: Malek Mechergui and Sarath Sreedharan<br><a href="papers/ALA2023_paper_10.pdf"><em>Goal Alignment: Re-analyzing Value Alignment Problems Using Human-Aware AI</em></a></li>
                                <li>Short Talk: Seongmin Kim, Woojun Kim, Jeewon Jeon, Youngchul Sung and Seungyul Han<br><a href="papers/ALA2023_paper_25.pdf"><em>Off-Policy Multi-Agent Policy Optimization with Multi-Step Counterfactual Advantage Estimation</em></a></li>
                            </ul>
                        </td>
                    </tr>
                    <tr>
                        <td>14:15-15:45</td>
                        <td><em><a href="#posterA"><b>Poster Session A</b></a></em></td>
                        <tr>
                            <tr>
                                <td>15:45-16:30</td>
                                <td><b>Coffee Break</b><br/></td>
                            </tr>
                            <tr><td>16:30-18:00</td><td><b>Session III - Chair: Caroline Wang</b></td><tr>
                                <tr>
                        <td>16:30-16:45</td>
                        <td>Long Talk: Rory Lipkis and Adrian Agogino<br><a href="papers/ALA2023_paper_33.pdf"><em>Discovery and Analysis of Rare High-Impact Failure Modes Using Adversarial RL-Informed Sampling</em></a></td>
                    </tr>
                    <tr>
                        <td>16:45-17:00</td>
                        <td>Long Talk: Montaser Mohammedalamen, Dustin Morrill, Alexander Sieusahai, Yash Satsangi and Michael Bowling<br><a href="papers/ALA2023_paper_8.pdf"><em>Learning to Be Cautious</em></a></td>
                    </tr>
                    <tr>
                        <td>17:00-18:00</td>
                        <td>Invited Talk: Peter Stone (UT Austin) <br/><em><a href="#talks2">Practical Reinforcement Learning:  Lessons from 30 years of Research</a></em></td>
                    </tr>
                    <tr>
                        <td>~19:00</td>
                        <td><b>Social Gathering</b> The Blind Beggar Pub (<a href="https://goo.gl/maps/m7Po2n8paTnffVPX8?coh=178571&entry=tt">Google Maps</a>)</td>
                    </tr>
                    </table>
                    <h4>Tuesday May 30</h4>
                    <table width="100%" >
                    <tr>
                        <td>08:30-10:00</td>
                        <td><b>Session IV - Chair: Connor Yates</b></td>
                        <tr>
                            <td>08:30-09:30</td>
                            <td>Invited Talk: Chris Amato (Northeastern University)<br/><em><a href="#talks3">Principled and Scalable Multi-Agent Reinforcement Learning</a></em></td>
                        </tr>
                    <tr>
                        <td>09:30-09:45</td>
                        <td>Philipp Altmann, Thomy Phan, Fabian Ritz, Claudia Linnhoff-Popien and Thomas Gabor<br><a href="papers/ALA2023_paper_22.pdf"><em>DIRECT: Learning from Sparse and Shifting Rewards using Discriminative Reward Co-Training</a></br></td>
                        </tr>
                        <tr>
                            <td>09:45-10:00</td>
                            <td>Henrik Müller, Lukas Berg and Daniel Kudenko<br><a href="papers/ALA2023_paper_28.pdf"><em>Using Incomplete and Incorrect Plans to Shape Reinforcement Learning in Long-Sequence Sparse-Reward Tasks</a></br></td>
                            </tr>
                            <tr>
                                <td>10:00-11:00</td>
                                <td><b>Coffee Break</b><br/></td>
                            </tr>
                            <tr><td>11:00-12:30</td><td><b>Session V - Chair: Roxana Rădulescu</b></tr>
                                <tr>
                                    <td>11:00-11:15</td>
                                    <td>Guanbao Yu, Umer Siddique and Paul Weng<br><a href="papers/ALA2023_paper_34.pdf"><em>Fair Deep Reinforcement Learning with Generalized Gini Welfare Functions</a></br></td>
                                        <tr>
                                            <td>11:15-11:30</td>
                                            <td>Long Talk: Manel Rodriguez-Soto, Roxana Radulescu, Juan Antonio Rodriguez Aguilar, Maite Lopez-Sanchez and Ann Nowe<br><a href="papers/ALA2023_paper_15.pdf"><em>Multi-objective reinforcement learning for guaranteeing alignment with multiple values</em></a></td>
                                        </tr>
                                        <tr>
                                            <td>11:30-12:30</td>
                                            <td><b>Short Talks, 6 minutes each in order:</b>
                                                <ul>
                                    <li>Simon Vanneste, Astrid Vanneste, Tom De Schepper, Siegfried Mercelis, Peter Hellinckx and Kevin Mets<br><a href="papers/ALA2023_paper_21.pdf"><em>Distributed Critics using Counterfactual Value Decomposition in Multi-Agent Reinforcement Learning</em></a></li>
                                    <li>Callum Rhys Tilbury, Filippos Christianos and Stefano V. Albrecht<br><a href="papers/ALA2023_paper_23.pdf"><em>Revisiting the Gumbel-Softmax in MADDPG</em></a></li>
                                    <li>Lukas Schäfer, Oliver Slumbers, Stephen McAleer, Yali Du, Stefano Albrecht and David Mguni<br><a href="papers/ALA2023_paper_37.pdf"><em>Ensemble Value Functions for Efficient Exploration in Multi-Agent Reinforcement Learning</em></a></li>
                                    <li>Robert Loftin, Mustafa Mert Çelikok, Herke Van Hoof, Samuel Kaski and Frans Oliehoek<br><a href="papers/ALA2023_paper_38.pdf"><em>Uncoupled Learning of Differential Stackelberg Equilibria with Commitments</em></a></li>
                                    <li>Jannis Weil, Johannes Czech, Tobias Meuser and Kristian Kersting<br><a href="papers/ALA2023_paper_45.pdf"><em>Know your Enemy: Investigating Monte-Carlo Tree Search with Opponent Models in Pommerman</em></a></li>
                                    <li>Sotirios Nikoloutsopoulos, Iordanis Koutsopoulos and Michalis Titsias<br><a href="papers/ALA2023_paper_46.pdf"><em>Personalized Federated Learning with Exact Distributed Stochastic Gradient Descent Updates</em></a></li>
                                    <li>Yash Satsangi and Paniz Behboudian<br><a href="papers/ALA2023_paper_48.pdf"><em>Bandit-Based Policy Invariant Explicit Shaping</em></a></li>
                                    <li>Dimitris Michailidis, Willem Röpke, Sennay Ghebreab, Diederik M. Roijers and Fernando P. Santos<br><a href="papers/ALA2023_paper_51.pdf"><em>Fairness in Transport Network Design - A Multi-Objective Reinforcement Learning Approach</em></a></li>
                                    <li>Mathieu Reymond, Florent Delgrange, Guillermo A. Pérez and Ann Nowé<br><a href="papers/ALA2023_paper_42.pdf"><em>WAE-PCN: Wasserstein-autoencoded Pareto Conditioned Networks</em></a></li>
                                                </ul>
                                            </td>
                                        </tr>
                    <tr>
                        <td>12:30-14:00</td>
                        <td><b>Lunch Break</b><br/></td>
                    </tr>
                    <tr><td>14:00-15:45</td><td><b>Short Talks & Poster Session - Chair: Gaurav Dixit</b></td></tr>
                    <tr>
                        <td>14:00-14:15</td>
                        <td><b>Short Talks, 6 minutes each in order:</b>
                            <ul>
                                <li>Prashank Kadam, Ruiyang Xu and Karl Lieberherr<br><a href="papers/ALA2023_paper_55.pdf"><em>Accelerating Neural MCTS Algorithms using Neural Sub-Net Structures</em></a></li>
                                <li>Alex Goodall and Francesco Belardinelli<br><a href="papers/ALA2023_paper_60.pdf"><em>Approximate  Shielding of Atari Agents for Safe Exploration</em></a></li>
                                <li>Luis Thomasini, Lucas Alegre, Gabriel De O. Ramos and Ana L. C. Bazzan<br><a href="papers/ALA2023_paper_69.pdf"><em>RouteChoiceGym: a Route Choice Library for Multiagent Reinforcement Learning</em></a></li>
                            </ul>
                        </td>
                    </tr>
                    <tr>
                        <td>14:15-15:45</td>
                        <td><em><a href="#posterB"><b>Poster Session B</b></a></em></td>
                        <tr>
                            <tr>
                                <td>15:45-16:30</td>
                                <td><b>Coffee Break</b><br/></td>
                            </tr>
                            <tr><td>16:30-18:00</td><td><b>Session VI - Chair: Diederik M. Roijer</b></td><tr>
                                <tr>
                                    <td>16:30-16:45</td>
                                    <td>Long Talk: Alain Andres, Lukas Schäfer, Esther Villar-Rodriguez, Stefano Albrecht and Javier Del Ser<br><a href="papers/ALA2023_paper_47.pdf"><em>Using Offline Data to Speed-up Reinforcement Learning in Procedurally Generated Environments</em></a></td>
                                </tr>
                                <tr>
                                    <td>16:45-17:00</td>
                                    <td>Long Talk: Adam Callaghan, Karl Mason and Patrick Mannion<br><a href="papers/ALA2023_paper_30.pdf"><em>Evolutionary Strategy guided Reinforcement Learning via MultiBuffer Communication</em></a></td>
                                </tr>
                                <tr>
                                    <td>17:00-18:00</td>
                                    <td>Panel Discussion With Invited Speakers<br/><em><a href="#"></a></em></td>
                                </tr>
                                <tr>
                                    <td>18:00</td>
                                    <td><b>Awards & Closing Remarks</b></td>
                                </tr>
                    </table>
                </div>
            </section>
            <section id="posters">
                <div id="posterA" class="container">
                    <h4>Poster Session A - Monday May 29 14:15-15:45</h4>
                    <p>All papers presented on day 1, together with:</p>
                    <ul>
                        <li>Armaan Garg and Shashi Shekhar Jha<br><a href="papers/ALA2023_paper_7.pdf"><em>Autonomous Flood Area Coverage using Decentralized Multi-UAV System with Directed Explorations</em></a></li>
                        <li>Seán Caulfield Curley, Karl Mason and Patrick Mannion<br><a href="papers/ALA2023_paper_9.pdf"><em>A Classification Based Approach to Identifying and Mitigating Adversarial Behaviours in Deep Reinforcement Learning Agents</em></a></li>
                        <li>Sebastian Schmid and Andreas Harth<br><a href="papers/ALA2023_paper_13.pdf"><em>Distributed Fault Detection For Multi-Agent Systems Based On Vertebrate Foraging</em></a></li>
                        <li>Maxime Toquebiau, Nicolas Bredeche, Faïz Ben Amar and Jae Yun Jun Kim<br><a href="papers/ALA2023_paper_16.pdf"><em>Joint Intrinsic Motivation for Coordinated Exploration in Multi-Agent Reinforcement Learning</em></a></li>
                        <li>Ridhima Bector, Hang Xu, Abhay Aradhya, Chai Quek and Zinovi Rabinovich<br><a href="papers/ALA2023_paper_18.pdf"><em>Should Importance of an Attack's Future be Determined by its Current Success?</em></a></li>
                        <li>Xue Yang, Enda Howley and Michael Schukat<br><a href="papers/ALA2023_paper_26.pdf"><em>ADT: Agent-based Dynamic Thresholding for Anomaly Detection</em></a></li>
                        <li>Abilmansur Zhumabekov, Daniel May, Tianyu Zhang, Aakash Krishna, Omid Ardakanian and Matthew Taylor<br><a href="papers/ALA2023_paper_31.pdf"><em>Ensembling Diverse Policies Improves Generalizability of Reinforcement Learning Algorithms in Continuous Control Tasks</em></a></li>
                        <li>Alexandra Cimpean, Pieter Libin, Youri Coppens, Catholijn Jonker and Ann Nowé<br><a href="papers/ALA2023_paper_39.pdf"><em>Towards Fairness In Reinforcement Learning</em></a></li>
                        <li>Anna Penzkofer, Simon Schaefer, Florian Strohm, Mihai Bâce, Stefan Leutenegger and Andreas Bulling<br><a href="papers/ALA2023_paper_59.pdf"><em>Int-HRL: Towards Intention-based Hierarchical Reinforcement Learning</em></a></li>
                        <li>Yuan Xue, Megha Khosla and Daniel Kudenko<br><a href="papers/ALA2023_paper_62.pdf"><em>Regulating Action Value Estimation in Deep Reinforcement Learning</em></a></li>
                        <li>Yuxuan Li, Qinglin Liu, Nan Lin and Matthew Taylor<br><a href="papers/ALA2023_paper_64.pdf"><em>Work in Progress: Integrating Human Preference and Human Feedback for Environmentally Adaptable Robotic Learning</em></a></li>
                    </ul>
                </div>
                <div id="posterB" class="container">
                    <h4>Poster Session B - Tuesday May 30 14:15-15:45</h4>
                    <p>All papers presented on day 2, together with:</p>
                    <ul>
                        <li>Bruno Rodrigues, Matthias Knorr, Ludwig Krippahl and Ricardo Gonçalves<br><a href="papers/ALA2023_paper_14.pdf"><em>Towards Explaining Actions of Learning Agents</em></a></li>
                        <li>Ridhima Bector, Hang Xu, Abhay Aradhya, Chai Quek and Zinovi Rabinovich<br><a href="papers/ALA2023_paper_19.pdf"><em>Poisoning the Well: Can We Simultaneously Attack a Group of Learning Agents?</em></a></li>
                        <li>Junlin Lu, Patrick Mannion and Karl Mason<br><a href="papers/ALA2023_paper_20.pdf"><em>Inferring Preferences from Demonstrations in Multi-objective Reinforcement Learning: A Dynamic Weight-based Approach</em></a></li>
                        <li>Louis Bagot, Lynn D'Eer, Steven Latre, Tom De Schepper and Kevin Mets<br><a href="papers/ALA2023_paper_24.pdf"><em>GPI-Tree Search: Algorithms for Decision-time Planning with the General Policy Improvement Theorem</em></a></li>
                        <li>Archana Vadakattu, Michelle Blom and Adrian Pearce<br><a href="papers/ALA2023_paper_35.pdf"><em>Strategy Extraction in Single-agent Games</em></a></li>
                        <li>Danila Valko and Daniel Kudenko<br><a href="papers/ALA2023_paper_40.pdf"><em>Increasing Energy Efficiency of Bitcoin Infrastructure with Reinforcement Learning and One-shot Path Planning for the Lightning Network</em></a></li>
                        <li>Jacobus Smit and Fernando P. Santos<br><a href="papers/ALA2023_paper_53.pdf"><em>Learning Fair Cooperation in Systems of Indirect Reciprocity</em></a></li>
                        <li>Md. Saiful Islam, Srijita Das, Sai Krishna Gottipati, William Duguay, Cloderic Mars, Jalal Arabneydi, Antoine Fagette, Matthew Guzdial and Matthew E. Taylor<br><a href="papers/ALA2023_paper_56.pdf"><em>WIP: Human-AI interactions in real-world complex environments using a comprehensive reinforcement learning framework</em></a></li>
                        <li>Ward Gauderis, Fabian Denoodt, Bram Silue, Pierre Vanvolsem and Andries Rosseau<br><a href="papers/ALA2023_paper_57.pdf"><em>Efficient Bayesian Ultra-Q Learning for Multi-Agent Games</em></a></li>
                        <li>Richard Willis and Michael Luck<br><a href="papers/ALA2023_paper_65.pdf"><em>Resolving social dilemmas through reward transfer commitments</em></a></li>
                        <li>Udari Madhushani, Kevin McKee, John Agapiou, Joel Leibo, Richard Everett, Thomas Anthony, Edward Hughes, Karl Tuyls and Edgar Duenez-Guzman<br><a href="papers/ALA2023_paper_67.pdf"><em>Heterogeneous Social Value Orientation Improves Meaningful Diversity in Various Incentive Structures</em></a></li>
                    </ul>
                </div>
            </section>
            -->

            

        <section id="accepted">
            <div class="container">
                <h3>Accepted Papers</h3>
                <p></p>                  
            
                <table style="width:100%">
                    <tr style="text-align:center">
                        <th>Paper #</th>
                        <th>Authors</th>
                        <th>Title</th>
                    </tr>
            <tr><td>2</td><td>Ram Rachum, Yonatan Nakar, William Tomlinson, Nitay Alon, Reuth Mirsky</td><td>Emergent Dominance Hierarchies in Reinforcement Learning Agents</td></tr>
            <tr><td>3</td><td>Simone Drago, Marco Mussi, Marcello Restelli, Alberto Maria Metelli</td><td>Intermediate Observations in Factored-Reward Bandits</td></tr>
            <tr><td>4</td><td>Kyle Crandall, Connor Yates, Corbin Wilhelmi</td><td>Lyapunov Guarantees for Learned Policies</td></tr>
            <tr><td>5</td><td>Marc Lanctot, John Schultz, Neil Burch, Max Olan Smith, Daniel Hennes, Thomas Anthony, Julien Perolat</td><td>Population-based Evaluation in Repeated Rock-Paper-Scissors as a Benchmark for Multiagent Reinforcement Learning</td></tr>
            <tr><td>7</td><td>Pascal Van der Vaart, Neil Yorke-Smith, Matthijs T. J. Spaan</td><td>Bayesian Ensembles for Exploration in Deep Q-Learning</td></tr>
            <tr><td>9</td><td>Jérôme Botoko Ekila, Jens Nevens, Lara Verheyen, Katrien Beuls, Paul Van Eecke</td><td>Decentralised Emergence of Robust and Adaptive Linguistic Conventions in Populations of Autonomous Agents Grounded in Continuous Worlds</td></tr>
            <tr><td>10</td><td>Hei Yi Mak, Flint Xiaofeng Fan, Luca A Lanzendörfer, Cheston Tan, Wei Tsang Ooi, Roger Wattenhofer</td><td>CAESAR: Enhancing Federated RL in Heterogeneous MDPs through Convergence-Aware Sampling with Screening</td></tr>
            <tr><td>11</td><td>Sunghoon Hong, Whiyoung Jung, Deunsol Yoon, Kanghoon Lee, Woohyung Lim</td><td>Agent-Oriented Centralized Critic for Asynchronous Multi-Agent Reinforcement Learning</td></tr>
            <tr><td>15</td><td>Nicole Orzan, Erman Acar, Davide Grossi, Roxana Rădulescu</td><td>Learning in Public Goods Games with Non-Linear Utilities: a Multi-Objective Approach</td></tr>
            <tr><td>16</td><td>Argha Boksi, Balaraman Ravindran</td><td>Inter-agent Transfer Learning in Communication-constrained Settings : A Student Initiated Advising Approach</td></tr>
            <tr><td>18</td><td>Brian Burns, Aravind Sundaresan, Pedro Sequeira, Vidyasagar Sadhu</td><td>Learning Sensor Control for Information Gain in Dynamic, Partially Observed and Sparsely Sampled Environments</td></tr>
            <tr><td>22</td><td>Alexandra Cimpean, Catholijn M Jonker, Pieter Jules Karel Libin, Ann Nowe</td><td>A Group And Individual Aware Framework For Fair Reinforcement Learning</td></tr>
            <tr><td>23</td><td>Bram M. Renting, Holger Hoos, Catholijn M Jonker </td><td>Multi-Agent Meeting Scheduling: A Negotiation Perspective</td></tr>
            <tr><td>24</td><td>Arnau Mayoral Macau, Manel Rodriguez-Soto, Maite López-Sánchez, Juan Antonio Rodriguez Aguilar, Enrico Marchesini, Alessandro Farinelli</td><td>An approximate process for designing ethical environments with multi-agent reinforcement learning</td></tr>
            <tr><td>25</td><td>Jonathan G. Faris, Conor F. Hayes, Andre R Goncalves, Kayla G. Sprenger, Daniel faissol, Brenden K. Petersen, Mikel Landajuela, Felipe Leno da Silva</td><td>Pareto Front Training For Multi-Objective Symbolic Optimization</td></tr>
            <tr><td>28</td><td>Zun Li, Michael Wellman</td><td>A Meta-Game Evaluation Framework for Deep Multiagent Reinforcement Learning</td></tr>
            <tr><td>29</td><td>Jérôme Arjonilla, Tristan Cazenave and Abdallah Saffidine</td><td>Enhancing Reinforcement Learning Through Guided Search</td></tr>
            <tr><td>32</td><td>Jérôme Arjonilla, Tristan Cazenave and Abdallah Saffidine</td><td>Perfect Information Monte Carlo with postponing reasoning</td></tr>
            <tr><td>33</td><td>	Radovan Haluška and Martin Schmid</td><td>Learning to Beat ByteRL: Exploitability of Collectible Card Game Agents</td></tr>
        </table>
    </div>
</section>



<!-- Six -->
<!--
    <section id="talks">
        <div class="container">
            <h3>Invited Talks</h3>
            <h4 id='talks1'>Shimon Whiteson</h4>
            <div style="width:100%;">
                <div style="width:35%; float:left;"><img src="images/shimon.jpg" width="90%" image-orientation="from-image"></div>
                <div style="width:65%; float:right;">
                    <p><b>Affiliation:</b> University of Oxford, Waymo UK</p>
                    <p><b>Website:</b> <a href="http://whirl.cs.ox.ac.uk/index.html" target="_blank">http://whirl.cs.ox.ac.uk/index.html</a></p>
                </div>
            </div>                    
            
            <p align="justify" class="title"><b>Title:</b> Title: Efficient & Realistic Simulation for Autonomous Driving
            </p>
            <p align="justify" class="abstract"><b>Abstract:</b> In this talk, I will discuss some of the key challenges in performing efficient and realistic simulation for autonomous driving, with a particular focus on how to train simulated agents that model the human road users, such as cars, cyclists, and pedestrians who share the road with autonomous vehicles. I will discuss the need for distributionally realistic agents and present two methods for training hierarchical agents to this end. Finally, I will discuss how the resulting simulator can be used to efficiently train a planning agent to control the autonomous vehicle itself.</p>
            <p align="justify" class="bio"><b>Bio:</b> Shimon Whiteson is a Professor of Computer Science at the University of Oxford and the Head of Research at Waymo UK. His research focuses on deep reinforcement learning and learning from demonstration, with applications in robotics and video games. He completed his doctorate at the University of Texas at Austin in 2007. He spent eight years as an Assistant and then an Associate Professor at the University of Amsterdam before joining Oxford as an Associate Professor in 2015. He was awarded a Starting Grant from the European Research Council in 2014, a Google Faculty Research Award in 2017, and a JPMorgan Faculty Award in 2019.
            </p>
            <p class="entry-footer"></p>                   

            <h4 id='talks2'>Peter Stone</h4>
            <div style="width:100%;">
                <div style="width:35%; float:left;"><img src="images/Peter_Headshot_2019.png" width="90%" image-orientation="from-image"></div>
                <div style="width:65%; float:right;">
                    <p><b>Affiliation:</b> The University of Texas at Austin</p>
                    <p><b>Website:</b> <a href="https://www.cs.utexas.edu/~pstone/" target="_blank">https://www.cs.utexas.edu/~pstone/</a></p>
                </div>
            </div>                    
            <p align="justify" class="title"><b>Title:</b> Practical Reinforcement Learning:  Lessons from 30 years of Research</p>
            <p align="justify" class="abstract"><b>Abstract:</b> The field of reinforcement learning (RL) has a long history of theoretical results that indicate when RL algorithms *should* work.  Throughout this history, there has been a complementary thread of research that tests the theoretical assumptions by seeking to determine when (and how) RL algorithms *do* work in practice.  
                
                Drawing on 30 years of research results, mostly from the Learning Agents Research Group at UT Austin, this talk will summarize lessons learned about practical RL into four high-level topics: 1) Representation - choosing the algorithm for the problem's representation and adapating the representation to fit the algorithm; 2) Interaction - with other agents and with human trainers; 3) Synthesis - of different algorithms for the same problem and of different concepts in the same algorithm; and 4) Mortality - dealing with the constraint that in most practical settings, opportunities for learning experience are limited.
                
                The talk will conclude with a brief introduction to one of the largest ever commercial deployments of an RL agent, Gran Turismo Sophy, which in 2021 won a head-to-head competition against four of the world's best drivers in the Gran Turismo high speed racing game.</a></p>
                <p></p>
                <p align="justify" class="bio"><b>Bio:</b> Dr. Peter Stone holds the Truchard Foundation Chair in Computer Science at the University of Texas at Austin. He is Associate Chair of the Computer Science Department, as well as Director of Texas Robotics. In 2013 he was awarded the University of Texas System Regents' Outstanding Teaching Award and in 2014 he was inducted into the UT Austin Academy of Distinguished Teachers, earning him the title of University Distinguished Teaching Professor. Professor Stone's research interests in Artificial Intelligence include machine learning (especially reinforcement learning), multiagent systems, and robotics. Professor Stone received his Ph.D in Computer Science in 1998 from Carnegie Mellon University. From 1999 to 2002 he was a Senior Technical Staff Member in the Artificial Intelligence Principles Research Department at AT&T Labs - Research. He is an Alfred P. Sloan Research Fellow, Guggenheim Fellow, AAAI Fellow, IEEE Fellow, AAAS Fellow, ACM Fellow, Fulbright Scholar, and 2004 ONR Young Investigator. In 2007 he received the prestigious IJCAI Computers and Thought Award, given biannually to the top AI researcher under the age of 35, and in 2016 he was awarded the ACM/SIGAI Autonomous Agents Research Award. Professor Stone co-founded Cogitai, Inc., a startup company focused on continual learning, in 2015, and currently serves as Executive Director of Sony AI America. </p>
                <p class="entry-footer"></p>                   
                
                
                
                <h4 id='talks3'>Christopher Amato</h4>
                <div style="width:100%;">
                    <div style="width:35%; float:left;"><img src="images/ChrisAmato.jpg" width="90%" image-orientation="from-image"></div>
                <div style="width:65%; float:right;">
                    <p><b>Affiliation:</b>Northeastern University</p>
                    <p><b>Website:</b> <a href="https://www.ccs.neu.edu/home/camato/index.html" target="_blank">https://www.ccs.neu.edu/home/camato/index.html</a></p>
                </div>
                </div>
                    <p class="title" align="justify"><b>Talk Title: Principled and Scalable Multi-Agent Reinforcement Learning</b></p>
                    <p class="abstract" align="justify"><b>Abstract: </b>The decreasing cost and increasing sophistication of hardware has created new opportunities for applications where teams of agents (e.g., robots, autonomous vehicles, AI software) can be deployed to solve complex problems. However, if such systems are to become widely deployable, we must develop the control and coordination methods that allow the agents to perform well in large real-world domains with significant uncertainty and communication limitations. I’ll first talk about some of the fundamental challenges and misunderstandings of multi-agent reinforcement learning along with promising future directions. In particular, I’ll discuss how 1) centralized critics are not strictly better than decentralized critics (and can be worse), and 2) state-based critics are unsound and work well only on a subclass of problems. I’ll also talk about some of our work on scalable reinforcement learning methods for asynchronous multi-agent systems. </p>
                    
                    <p align="justify" class="bio"><b>Bio: </b>Christopher Amato is an Associate Professor at Northeastern University where he leads the Lab for Learning and Planning in Robotics. He has published over 60 papers in leading artificial intelligence, machine learning and robotics conferences (including winning a best paper prize at AAMAS-14 and being nominated for the best paper at RSS-15, AAAI-19, AAMAS-21 and MRS-21). He has also won several awards such as Amazon Research Awards and an NSF CAREER Award. His research focuses on reinforcement learning in partially observable and multi-agent/multi-robot systems.</p>
                    <p class="entry-footer"></p>                   
                </div>
            </section>
        -->

            <!-- Six -->
            <!--

                <section id="awards">
                    <div class="container">
                        <h3>Awards</h3>
                        
                        <h4 id='bestpaperaward'>Best Paper Award</h4>
            -->
                        <!--<p align="justify" class="title"><b></b> Sponsored by Neural Computing & Applications</a></p>-->
                        <!--<p>We are pleased to announce the best paper of ALA 2023, sponsored by Neural Computing & Applications, is Fair Deep Reinforcement Learning with Generalized Gini Welfare Functions, by Guanbao Yu, Umer Siddique and Paul Weng!</p>-->
                    
                    
                    <!--
                        <h4 id='visionarypaperaward'>Visionary Paper Award</h4>
                        
                    <table style="width:100%">
                        <tr><td>32</td><td> Conor F. Hayes, Diederik M. Roijers, Enda Howley and Patrick Mannion</td><td><em><a target='_blank' href='papers/ALA2022_paper_32.pdf'> Multi-Objective Distributional Value Iteration</a></td><td><em><a target='_blank' href='https://youtu.be/BqqX1U0Njxg'> [video]</a></em></td></tr>
                    </table>

                    <h4 id='cogmentchallengewinner'>Cogment Challenge Winners</h4>
                    <p align="justify" class="title"><b></b> Sponsored by AI Redefined</a></p>                    
                    <table style="width:100%">
                        <tr><td>36</td><td> Chaitanya Kharyal, Tanmay Sinha and Matthew Taylor</td><td><em><a target='_blank' href='papers/ALA2022_paper_36.pdf'> Work-in-Progress: Multi-Teacher Curriculum Design for Sparse Reward Environments</a></td><td><em><a target='_blank' href='https://youtu.be/v__MJvfjiBw'> [video]</a></em></td></tr>
                        <tr><td>5</td><td>Benjamin Wexler, Elad Sarafian and Sarit Kraus</td><td><em><a target='_blank' href='papers/ALA2022_paper_5.pdf'> Analyzing and Overcoming Degradation in Warm-Start Off-Policy Reinforcement Learning</a></td><td><em><a target='_blank' href='https://youtu.be/_cveeScjMlY'> [video]</a></em></td></tr>
                    </table>
                    <p class="entry-footer"></p>                   
                    -->
        <!--
                </div>
            </section>
        -->
            
            
            <!-- Seven -->
            <!--
                <section id="pc">
                    <div class="container">
                        <h3>Programe Committee</h3>         
                        
                        <ul>
                            <li>Adrian Agogino, University of California Santa Cruz, USA</li>
                            <li>Lucas Alegre, UFRGS, BRA</li>
                            <li>Muhammad Arrasy-Rahman, The University of Texas at Austin, USA</li>
                            <li>Raphael Avalos, Vrije Universiteit Brussel, BEL</li>
                            <li>Angel Ayala, Universidade de Pernambuco, BRA</li>
                            <li>Wolfram Barfuss, Tuebingen AI Center, University of Tuebingen, GER</li>
                            <li>Rodrigo Bonini, Federal University of ABC (UFABC), BRA</li>
                            <li>Roland Bouffanais, University of Ottawa, CAN</li>
                            <li>Adam Callaghan, University of Galway, IRL</li>
                            <li>Mustafa Mert Çelikok, Aalto University FIN</li>
                            <li>Raphael Cobe, Sao Paulo State University, BRA</li>
                            <li>Francisco Cruz, Deakin, AUS</li>
                            <li>Jiaxun Cui, The University of Texas at Austin, USA</li>
                            <li>Felipe&nbsp;leno Da&nbsp;silva, LLNL, USA</li>
                            <li>Gaurav Dixit, Oregon State University, USA</li>
                            <li>Florian Felten, SnT, University of Luxembourg, LUX</li>
                            <li>Elias Fernández Domingos, MLG, Université Libre de Bruxelles; AI-lab, Vrije Universiteit Brussels, BEL</li>
                            <li>Julian Garcia, Monash University, AUS</li>
                            <li>Ruben Glatt, Lawrence Livermore National Laboratory, USA</li>
                            <li>Brent Harrison, University of Kentucky, USA</li>
                            <li>Conor F Hayes, NUI Galway, IRL</li>
                            <li>Thommen Karimpanal George, Deakin University, AUS</li>
                            <li>Sammie Katt, Northeastern University, USA</li>
                            <li>Matt Knudson, NASA, USA</li>
                            <li>Johan Källström, Linköping University, SWE</li>
                            <li>Mikel Landajuela Larma, Lawrence Livermore National Laboratory, USA</li>
                            <li>Junlin Lu, University of Galway, IRL</li>
                            <li>Udari Madhushani, Princeton University, USA</li>
                            <li>Patrick Mannion, National University of Ireland Galway, IRL</li>
                            <li>Karl Mason, University of Galway, IRL</li>
                            <li>Nicolás Navarro-Guerrero, Deutsches Forschungszentrum für Künstliche Intelligenz (DFKI), GER</li>
                            <li>Frans Oliehoek, Delft University of Technology, NLD</li>
                            <li>Bei Peng, University of Liverpool, GBR</li>
                            <li>Roxana Radulescu, Vrije Universiteit Brussel, BEL</li>
                            <li>Gabriel De O.  Ramos, Universidade do Vale do Rio dos Sinos, BRA</li>
                            <li>Mathieu Reymond, Vrije Universiteit Brussel, BEL</li>
                            <li>Diederik M.  Roijers, Vrije Universiteit Brussel &amp; HU University of Applied Sciences Utrecht, BEL</li>
                            <li>Willem Röpke, Vrije Universiteit Brussel, BEL</li>
                            <li>Fernando Santos, University of Amsterdam, NLD</li>
                            <li>Miguel Solis, Universidad Andrés Bello, CHL</li>
                            <li>Denis Steckelmacher, Vrije Universiteit Brussel, BEL</li>
                            <li>Paolo Turrini, University of Warwick, GBR</li>
                            <li>Peter Vamplew, Federation University Australia, AUS</li>
                            <li>Miguel Vasco, INESC-ID, PRT</li>
                            <li>Vítor V.  Vasconcelos, University of Amsterdam, NLD</li>
                            <li>Caroline Wang, U Texas, USA</li>
                            <li>Connor Yates, Oregon State University, USA</li>
                            <li>Junpei Zhong, The Hong Kong Polytechnic University, HKG</li>
                            <li>Changxi Zhu, Utrecht University, NLD</li>
                        </ul>

                    </div>
                </section>
            -->

            
            <!-- eight -->
            <section id="organization">
                <div class="container">
                    <h3>Organization</h3>
                    This year's workshop is organised by:
                    <ul>
                        <li><a href="https://avalos.fr" target="_blank">Raphael Avalos</a> (Vrije Universiteit Brussel, BE) </li>
                        <li>David Milec (Czech Technical University in Prague, CZ) </li>
                        <li>Henrik M&uuml;ller (Leibniz University Hannover, DE) </li>
                        <li><a href="https://carolinewang01.github.io" target="_blank">Caroline Wang</a> (University of Texas at Austin, US) </li>
                        <li><a href="https://yatesco.org" target="_blank">Connor Yates</a> (U.S. Naval Research Laboratory, US)</li>
                    </ul>
                    
                    Senior Steering Committee Members:
                    <ul>
                        <li>Enda Howley (University of Galway, IE)</li>
                        <li>Daniel Kudenko (University of York, UK)</li>
                        <li>Patrick Mannion (University of Galway, IE)</li>
                        <li>Ann Now&eacute; (Vrije Universiteit Brussel, BE)</li>
                        <li>Sandip Sen (University of Tulsa, US)</li>
                        <li>Peter Stone (University of Texas at Austin, US)</li>
                        <li>Matthew Taylor (University of Alberta, CA)</li>
                        <li>Kagan Tumer (Oregon State University, US)</li>
                        <li>Karl Tuyls (University of Liverpool, UK)</li>
                    </ul>
                </div>
            </section>
            
            
            
            <!--
            <section id="sponsor">
                <div class="container">
                    <h3>Sponsorship</h3>
                    <p align="justify">The ALA 2022 Best Paper Award is kindly sponsored by the Springer journal <a href="https://www.springer.com/computer/ai/journal/521" target="_blank"> Neural Computing and Applications</a>.</p>
                    <a href="https://www.springer.com/computer/ai/journal/521" target='_blank'><img src='images/nca.jpg' height='200px' alt='NCA' /></a>
                </div>
            </section>

            <section id="ai_ethics">
                <div class="container">
                    <h3>Trustworthy Adaptive and Learning Agents</h3>
                    <p align="justify">Authors and attendees of ALA 2022 who are interested in trustworthiness in agent-based systems are invited to submit their work to a topical collection (TC) on Trustworthy Adaptive and Learning Agents (TALA).
                    This TC solicits original research articles, reviews/surveys, and opinion pieces/commentaries relating to trustworthiness in agent-based systems, including those that employ learning and/or adaptation.
                    The TALA TC has an open call for papers; it is not necessary to submit preliminary work to the ALA workshop in order to have your manuscript considered for publication in this TC.</p>
                    <p align="justify"><a href="https://www.springer.com/journal/43681/updates/19318686" target="_blank"> AI and Ethics</a></p>
                    <a href="https://www.springer.com/computer/ai/journal/521" target='_blank'><img src='images/ai_ethics.jpg' height='200px' alt='NCA' /></a>
                </div>
            </section>
            -->
            
            <!-- ten -->
            <section id="contact">
                <div class="container">
                    <h3>Contact</h3>
                    <p align="justify">If you have any questions about the ALA workshop, please contact the organizers at: <br/>
                    ala.workshop.2024 AT gmail.com
                    </p>
                    <p> For more general news, discussion, collaboration and networking opportunities with others interested in Adaptive Learning Agents then please join our Linkedin Group
                    <a class="fa" href="https://www.linkedin.com/groups/4412140/" >
                        <i class="fa fa-linkedin"></i>
                    </a> </p>
                </div>
            </section>
        
        <!-- Footer -->
        <section id="footer">
            <div class="container">
                <ul class="copyright">
                    <li>&copy; Adaptive Learning Agents Workshop 2024. All rights reserved.</li>
                    <li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
                    <li>Icons made by <a href="https://www.flaticon.com/authors/freepik" title="Freepik">Freepik</a> from <a href="https://www.flaticon.com/" title="Flaticon">www.flaticon.com</a> are licensed by <a href="http://creativecommons.org/licenses/by/3.0/" title="Creative Commons BY 3.0" target="_blank">CC 3.0 BY</a></li>
                    <!--<li>Header image by <a href="https://commons.wikimedia.org/wiki/File:Big_Ben_at_sunset_-_2014-10-27_17-30.jpg">Colin from Wikimedia Commons</a>, licensed under <a href="https://creativecommons.org/licenses/by-sa/4.0/" title="Creative Commons BY-SA 4.0" target="_blank">CC BY-SA 4.0</a></li>-->
                    <li>Header image by <a href="https://commons.wikimedia.org/wiki/File:Auckland_Skyline_as_seen_from_Devonport_20100128_3.jpg">DXR</a>, licensed under <a href="https://creativecommons.org/licenses/by-sa/4.0" title="Creative Commons BY-SA 4.0" target="_blank">CC BY-SA 4.0</a>, via Wikimedia Commons</li>
                </ul>
            </div>
        </section>
        
        </div>
        
        <!-- Scripts -->
        <script src="assets/js/jquery.min.js"></script>
        <script src="assets/js/jquery.scrollex.min.js"></script>
        <script src="assets/js/jquery.scrolly.min.js"></script>
        <script src="assets/js/browser.min.js"></script>
        <script src="assets/js/breakpoints.min.js"></script>
        <script src="assets/js/util.js"></script>
        <script src="assets/js/main.js"></script>
        
    </body>
</html>
