<!DOCTYPE HTML>
<!--
Read Only by HTML5 UP
html5up.net | @ajlkn
Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->

<html>
    <head>
        <title>ALA 2024</title>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
        <meta name="google-site-verification" content="aK65vKjdK-pwXkpxs-JBibUAgOiIT_3Kq3S66UUr1N8" />
        <link rel="stylesheet" href="assets/css/main.css" />
        <link rel="icon" type="image/png" href="images/icons/robot.png"/>
        <!-- Global site tag (gtag.js) - Google Analytics -->
        <script async src="https://www.googletagmanager.com/gtag/js?id=G-3WQZBEV8XB"></script>
        <script>
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());

          gtag('config', 'G-3WQZBEV8XB');
        </script>
        
    </head>
    <body class="is-preload">
        
        <!-- Header -->
        <section id="header">
            <header>
                <!--<span class="image avatar"><img src="images/avatar.jpg" alt="" /></span>-->
                <h1 id="logo"><a href="#">ALA 2024</a></h1>
                <p style="color:#FFF2D2">Adaptive and Learning Agents Workshop<br />
                at AAMAS, Auckland, NZ</p>
            </header>
            <nav id="nav">
                <ul>
                    <li><a href="#news" class="active">News</a></li>
                    <li><a href="#about">About</a></li>
                    <li><a href="#dates">Important Dates</a></li>
                    <li><a href="#submission">Submission Details</a></li>
                    <!--<li><a href="#challenge">ALA-Cogment Challenge</a></li>-->
                    <li><a href="#journal">Journal Special Issue</a></li>
                    <li><a href="#program">Program</a></li>
                    <!--<li><a href="#posters">Poster Sessions</a></li>-->
                    <li><a href="#accepted">Accepted Papers</a></li>
                    <li><a href="#talks">Invited Talks</a></li>
                    <!--<li><a href="#awards">Awards</a></li>-->
                    <li><a href="#pc">Program Committee</a></li>
                    <li><a href="#organization">Organization</a></li>
                    <!--<li><a href="#sponsor">Sponsorship</a></li>-->
                    <!--<li><a href="#ai_ethics">AI & Ethics</a></li>-->
                    <li><a href="#contact">Contact</a></li>
                    
                </ul>
            </nav>
            <footer>
                <ul class="icons">
                    <li><a href="https://www.linkedin.com/groups/4412140/" class="icon fa-linkedin"><span class="label">Linkedin</span></a></li>
                    <li><a href="mailto:ala.workshop.2024@gmail.com" class="icon fa-envelope"><span class="label">Email</span></a></li>
                </ul>
            </footer>
        </section>
        
        <!-- Wrapper -->
        <div id="wrapper">
            
            <!-- Main -->
            <!-- News -->
            <section id="news">
                <div id="main">
                    <div class="image main" data-position="center">
                        <img src="images/2560px-Auckland_Skyline_as_seen_from_Devonport_20100128_3.jpg" alt=""/>
                        <h2 id="banner-header" style="color:#FFF2D2">ALA 2024</h2>
                        <h3 id="banner-description" style="color:#FFF2D2">6 &amp; 7 May 2024, Auckland, NZ</h3>
                    </div>
                    <div class="container">
                        <h3>News</h3>
                        <ul>
<!--
                            <li> 08 May 2022: We invite all authors and participants to join our <a href="https://join.slack.com/t/ala2022/shared_invite/zt-18b830rie-9DBK_5AMQ__kqrrXX5cnqg" target="_blank">Slack workspace</a>! Check out the <a href="#program">program</a> for more details.</li>
                            <li> 08 May 2022: All video presentations have been uploaded to the <a href="https://www.youtube.com/channel/UCbmHKFUVThoAweXhRxtAm_Q/playlists" target="_blank">ALA YouTube channel</a>!.</li>
-->
<!--

                            <li>24 June: Best paper is announced in the <a href="#awards"><em>awards</em></a>.</li>
                            <li>8 May 2023: Camera-ready copies of all papers are viewable in the <a href="#program"><em>program</em></a>.</li>
                            <li>4 May 2023: Stay tuned for the camera-ready PDF's of each paper, which will be available on the website shortly.</li>
                            <li>3 May 2023: The <a href="#program"><em>program</em></a> for the workshop is now available. </li>
                            <li>3 May 2023: We are excited to announce Shimon Whiteson as a keynote speaker for ALA 2023. </li>
                            <li>25 April 2023: We are excited to announce Peter Stone as a keynote speaker for ALA 2023. </li>
                            <li>21 April 2023: We are excited to announce Christopher Amato as a keynote speaker for ALA 2023. </li>
                            
                            <li>17 April 2023: Information regarding the Neural Computing & Applications Journal Special Issue and Best Paper Award are now posted.</li>
                            <li>31 March 2023: The list of <a href="#accepted">accepted papers</a> is now online.</li>
                            <li>24 March 2023: Stay tuned! ALA 2023 acceptances will be announced on March 27th.</a></li>
                            <li>24 Jan 2023: ALA 2023 submission deadline has been extended to 24 Feb 2023 23:59 UTC </a></li>
                            <li>22 Dec 2022: ALA 2023 Submission Link can be found <a href="https://easychair.org/my/conference?conf=ala2023" target="_blank">here</a></li>
                            <li>22 Dec 2022: ALA Call for Papers can be found <a href="https://easychair.org/my/conference?conf=ala2023" target="_blank">here</a></li>
                        -->
                            <li>1 May 2024: We are excited to announce Ann Now√© as a keynote speaker for ALA 2024. </li>
                            <li>28 April 2024: Camera-ready copies of all papers are viewable in the <a href="#program"><em>program</em></a>.</li>
                            <li>28 April 2024: The <a href="#program"><em>program</em></a> for the workshop is now available. </li>
                            <li>25 April 2024: We are excited to announce Michael Wellman as a keynote speaker for ALA 2024. </li>
                            <li>22 April 2024: We are excited to announce Marc Lanctot as a keynote speaker for ALA 2024. </li>
                            <li>19 April 2024: The list of <a href="#accepted">accepted papers</a> is now online.</li>
                            <li>21 Mar 2024: The deadline for the camera-ready version of accepted papers has been extended to 19 Apr 2024</a></li>
                            <li>1 Mar 2024: The final decisions for ALA 2024 will be slightly delayed. Due to the overall lower number of submissions this year, the Workshop on Reinforcement Learning in Games will be merged into ALA and unifying the review process will take a few more days. Thanks for your patience!</a></li>
                            <li>9 Feb 2024: ALA 2024 submission deadline has been further extended to 12 Feb 2024 23:59 UTC </a></li>
                            <li>29 Jan 2024: ALA 2024 submission deadline has been extended to 9 Feb 2024 23:59 UTC </a></li>
                            <li>4 Dec 2023: ALA 2024 Website goes live!</li>
                        </ul>
                    </div>
                    </section>
            <!-- One -->
            <section id="about">
                <div class="container">
                    <header class="major">
                        <h3>ALA 2024 - Workshop at <a href="https://www.aamas2024-conference.auckland.ac.nz/" target="_blank">AAMAS 2024</a></h3>
                        <p align="justify">Adaptive and Learning Agents (ALA) encompasses diverse fields such as Computer Science, Software Engineering, Biology, as well as
                        Cognitive and Social Sciences. The ALA workshop will focus on agents and multiagent systems which employ learning or adaptation.</p>
                    </header>
                    <p align="justify">This workshop is a continuation of the long running AAMAS series of workshops on adaptive agents, now in its sixteenth year. Previous editions of this workshop may be found at the following urls:</p>
                    <ul>
                        <li><a href="https://alaworkshop2023.github.io/" target="_blank">ALA-23</a></li>
                        <li><a href="https://ala2022.github.io/" target="_blank">ALA-22</a></li>
                        <li><a href="http://ala2021.vub.ac.be" target="_blank">ALA-21</a></li>
                        <li><a href="http://ala2020.vub.ac.be" target="_blank">ALA-20</a></li>
                        <li><a href="http://ala2019.vub.ac.be" target="_blank">ALA-19</a></li>
                        <li><a href="http://ala2018.it.nuigalway.ie" target="_blank">ALA-18</a></li>
                        <li><a href="http://ala2017.it.nuigalway.ie/" target="_blank">ALA-17</a></li>
                        <li><a href="http://ala2016.csc.liv.ac.uk/" target="_blank">ALA-16</a></li>
                        <li><a href="http://ala2015.csc.liv.ac.uk/" target="_blank">ALA-15</a></li>
                        <li><a href="http://swarmlab.unimaas.nl/ala2014/" target="_blank">ALA-14</a></li>
                        <li><a href="http://swarmlab.unimaas.nl/ala2013/" target="_blank">ALA-13</a></li>
                        <li><a href="http://ai.vub.ac.be/ALA2012/" target="_blank">ALA-12</a></li>
                        <li><a href="http://como.vub.ac.be/ALA2011/" target="_blank">ALA-11</a></li>
                        <li><a href="http://www-users.cs.york.ac.uk/%7Ekudenko/ala10/" target="_blank">ALA-10</a></li>
                        <li><a href="http://teamcore.usc.edu/taylorm/ALA09/" target="_blank">ALA-09</a></li>
                        <li><a href="http://ki.informatik.uni-wuerzburg.de/%7Ekluegl/ALAMAS.ALAg/" target="_blank">ALAMAS+ALAg-08</a></li>
                        <li><a href="http://web.engr.oregonstate.edu/%7Ektumer/conferences/alag07.html" target="_blank">ALAg-07</a></li>
                        <!--  <li><a href="http://www.cs.unimaas.nl/alamas/">ALAMAS-07</a></li> -->
                        <li><a href="http://www-users.cs.york.ac.uk/%7Ekazakov/aamas/">Earlier editions</a> </li>
                    </ul>
                    <p align="justify">The goal of this workshop is to increase awareness of and interest in adaptive agent research, encourage collaboration and give a representative overview of current research in the area of adaptive and learning agents and multi-agent systems. It aims at bringing together not only scientists from different areas of computer science (e.g. agent architectures, reinforcement learning, evolutionary algorithms) but also from different fields studying similar concepts (e.g. game theory, bio-inspired control, mechanism design).</p>
                    
                    <p align="justify">The workshop will serve as an inclusive forum for the discussion of ongoing or completed work covering both theoretical and practical aspects of adaptive and learning agents and multi-agent systems.</p>
                    
                    <p align="justify">This workshop will focus on all aspects of adaptive and learning agents and multi-agent systems with a particular amphasis on how to modify established learning techniques and/or create new learning paradigms to address the many challenges presented by complex real-world problems. The topics of interest include but are not limited to:</p>
                    
                    <ul>
                        <li>Novel combinations of reinforcement and supervised learning approaches</li>
                        <li>Integrated learning approaches using reasoning modules like negotiation, trust, coordination, etc..</li>
                        <li>Supervised and semi-supervised multi-agent learning</li>
                        <li>Reinforcement learning (single- and multi-agent)</li>
                        <li>Novel deep learning approaches for adaptive single- and multi-agent systems</li>
                        <li>Multi-objective optimisation in single- and multi-agent systems</li>
                        <li>Planning (single- and multi-agent)</li>
                        <li>Reasoning (single- and multi-agent)</li>
                        <li>Distributed learning</li>
                        <li>Adaptation and learning in dynamic environments</li>
                        <li>Evolution of agents in complex environments</li>
                        <li>Co-evolution of agents in a multi-agent setting</li>
                        <li>Cooperative exploration and learning to cooperate and collaborate</li>
                        <li>Learning trust and reputation</li>
                        <li>Communication restrictions and their impact on multi-agent coordination</li>
                        <li>Design of reward structure and fitness measures for coordination</li>
                        <li>Scaling learning techniques to large systems of learning and adaptive agents</li>
                        <li>Emergent behaviour in adaptive multi-agent systems</li>
                        <li>Game theoretical analysis of adaptive multi-agent systems</li>
                        <li>Neuro-control in multi-agent systems</li>
                        <li>Bio-inspired multi-agent systems</li>
                        <li>Human-in-the-loop learning systems</li>
                        <li>Applications of adaptive and learning agents and multi-agent systems to real world complex systems</li>
                    </ul>
                    
                    <p align="justify">Extended and revised versions of papers presented at the workshop will be eligible for inclusion in a journal special issue (see below).</p>
                    <p class="entry-footer"></p>
                </div>
            </section>
            
            <!-- Two -->
            <section id="dates">
                <div class="container">
                    <h3>Important Dates</h3>
                    
                    <ul class="feature-icons">
                        
                        <li class="fa-telegram">Submission Deadline:<s> 5 February 2024 9 February 2024 </s>
                            &nbsp;&nbsp;<font color="#4872A6"><b>12 February 2024</b></font></li>
                        <li class="fa-bell">Notification of acceptance: <font color="#4872A6"><b>4 March  2024</b></font>
                        <li class="fa-file-pdf-o">Camera-ready copies: <s> 25 March 2024 </s>
                            &nbsp;&nbsp;<font color="#4872A6"><b>19 April 2024</b></font></li>
                        <li class="fa-users">Workshop:            <b>6 - 7 May 2024</b></li>
                    
                    </ul>
                </div>
            </section>
            
            <!-- Three -->
                <section id="submission">
                    <div class="container">
                        <h3>Submission Details</h3>
                        <p align="justify">Papers can be submitted through <a href="https://openreview.net/group?id=AAMAS/2024/Workshop/ALA" alt="" target="_blank">OpenReview</a>.</p>
                        <p align="justify">We invite submission of original work, up to 8 pages in length (excluding references) in the ACM proceedings format (i.e. following the AAMAS formatting instructions). This includes work that has been accepted as a poster/extended abstract at AAMAS 2024. Keeping with previous ALA guidelines, papers are limited to 8 pages plus references. Additionally, we welcome submission of preliminary results, i.e. work-in-progress, as well as visionary outlook papers that lay out directions for future research in a specific area, both up to 6 pages in length, although shorter papers are very much welcome, and will not be judged differently. Finally, we also accept recently published journal papers in the form of a 2 page abstract.</p>
                        <p align="justify">Furthermore, <strong> for submissions that were rejected or accepted as extended abstracts at AAMAS</strong>, authors need to also append the received reviews and a pdfdiff.</p>
                        <p align="justify">All submissions will be peer-reviewed (doubl-blind). Accepted work will be allocated time for poster and possibly oral presentation during the workshop. In line with AAMAS, the workshop will be <strong>fully offline</strong>. Extended versions of original papers presented at the workshop will also be eligible for inclusion in a post-proceedings journal special issue.  </p>
                        
                        <p align="justify">When preparing your submission for ALA 2024, please be sure to remove the AAMAS copyright block, citation information and running headers. You leave the submission id in the AAMAS template empty as we use OpenReview instead of easy chair. Please replace the AAMAS copyright block in the main.tex file from the AAMAS template with the following:
                            <pre>
    \setcopyright{none}
    \acmConference[ALA '24]{Proc.\@ of the Adaptive and Learning Agents Workshop (ALA 2024)}
    {May 6-7, 2024}{Auckland, \url{https://ala2024.github.io/}}{Avalos, Milec, M\"uller, Wang, Yates (eds.)}
    \copyrightyear{2024}
    \acmYear{2024}
    \acmDOI{}
    \acmPrice{}
    \acmISBN{}
    \settopmatter{printacmref=false}
                            </pre>
                        </p>
                        <p align="justify">For the submission of the camera-ready paper make sure to submit the deanonymized version with the replaced copyright block above.</p>
                </div>
            </section>

            <!-- Three -->
            <!--
            <section id="challenge">
                <div class="container">
                    <h3>ALA-Cogment Challenge</h3>
                    <p align="justify">All accepted ALA papers will be eligable to take part in the <a href="https://ai-r.com/aamas-2022-welcome-to-the-ala-cogment-challenge/" alt="" target="_blank">ALA-Cogment Challenge</a>. The ALA-Cogment Challenge offers a total prize pool of $10,000. </p>

                    <p align="justify">Cogment is an open-source framework for distributed multi-actor training, deployment, and operations. To take part in the competition you must submit a paper to ALA by 11-Feb-2022. Then all accepted ALA particiapants must, by April 30, 2022:

                        <ul>
                        <li> Sign up for the <a href="https://eyrwknioxo8.typeform.com/to/j4jMvQxp" alt="" target="_blank">ALA-Cogment Challenge.</a></li>
                        <li>Cite Cogment in your paper.</li>
                        <li>Implement an experimental setup using Cogment for your submitted paper and share it with the ALA-Cogment Challenge evaluation team (e.g. in a GitHub repo or in a zip file). We strongly encourage authors to publish their code to meet this requirement.</li>
                        </ul>


                    </p>


                    <p align="justify">We will award up to three grand prizes to ALA-Cogment Challenge submissions that make the best use of Cogment for applications or for fundamental research. Grand prizes will be awarded according to criteria that include (but are not limited to):

                        <ul>
                        <li>The richness of the submission‚Äôs Cogment usage with respect to agents, implementations, environments, benchmarking, and evaluations.</li>
                        <li>The creative involvement of human actors or evaluators during the submission‚Äôs Cogment training or validation process. </li>
                        <li>The complexity of the AI problem being addressed with Cogment.</li>
                        </ul>

                    We will announce the grand prize results live during the May 9-10, 2022 workshop. Further details about the competition can be found here: <a href="https://ai-r.com/aamas-2022-welcome-to-the-ala-cogment-challenge/" alt="" target="_blank">https://ai-r.com/aamas-2022-welcome-to-the-ala-cogment-challenge/</a>
                    </p>


                    
                </div>
            </section>
            -->
            
            <!-- Four -->
            <section id="journal">
                <div class="container">
                    <h3>Journal Special Issue</h3>
                    
                    <p align="justify">We are delighted to announce that extended versions of all original contributions at ALA 2024 will be eligible for inclusion in a special issue of the Springer journal <a href="https://www.springer.com/computer/ai/journal/521" alt="https://www.springer.com/computer/ai/journal/521" target="_blank">Neural Computing and Applications</a> (Impact Factor 6.0). The deadline for submitting extended papers will be 15 November 2024.</p>
                    <a href="https://www.springer.com/computer/ai/journal/521" target='_blank'><img src='images/nca.jpg' height='200px' alt='NCA' /></a>
                    
                    <p align="justify">For further information please contact the workshop organizers and Patrick Mannion.</p>
                    <p class="entry-footer"></p>
                    
                </div>
            </section>
            
            <!-- Five -->
            <section id="program">
                <div class="container">
                    <h3>Program</h3>
                    <p>All times are presented in local Auckland time.</p>
                    <h4>Monday May 6</h4>
                    <table width="100%" >
                    <tr>
                        <td></td>
                        <td><b>Welcome &amp; Opening Remarks</b>
                    </tr>
                    <tr>
                        <td>09:00-10:00</td>
                        <td><b>Session I - Chair: Connor Yates</b></td>
                        <tr>
                            <td>09:00-10:00</td>
                            <td>Invited Talk: Marc Lanctot (Deepmind)<br/><em><a href="#talks1">Game-Theoretic Approaches to Adaptive Learning Agents in Strategic Environments</a></em></td>
                    </tr>
                    <tr>
                        <td>10:00-10:45</td>
                        <td><b>Coffee Break</b><br/></td>
                    </tr>
                    <tr><td>10:45-12:30</td><td><b>Session II - Chair: David Milec</b></tr>
                    <tr>
                        <td>10:45-11:05</td>
                        <td>Long Talk: Bram M. Renting, Holger Hoos, Catholijn M Jonker<br><a href="papers/ALA2024_paper_23.pdf"><em>Multi-Agent Meeting Scheduling: A Negotiation Perspective</em></a></td>
                    <tr>
                        <td>11:05-11:25</td>
                        <td>Long Talk: Pascal Van der Vaart, Neil Yorke-Smith, Matthijs T. J. Spaan<br><a href="papers/ALA2024_paper_07.pdf"><em>Bayesian Ensembles for Exploration in Deep Q-Learning</em></a></td>
                    </tr>
                    <tr>
                        <td>11:25-11:45</td>
                        <td>Long Talk: Hei Yi Mak, Flint Xiaofeng Fan, Luca A Lanzend√∂rfer, Cheston Tan, Wei Tsang Ooi, Roger Wattenhofer<br><a href="papers/ALA2024_paper_10.pdf"><em>CAESAR: Enhancing Federated RL in Heterogeneous MDPs through Convergence-Aware Sampling with Screening</em></a></td>
                    </tr>
                    <tr>
                        <td>11:45-12:05</td>
                        <td>Long Talk: Sunghoon Hong, Whiyoung Jung, Deunsol Yoon, Kanghoon Lee, Woohyung Lim<br><a href="papers/ALA2024_paper_11.pdf"><em>Agent-Oriented Centralized Critic for Asynchronous Multi-Agent Reinforcement Learning</em></a></td>
                    </tr>
                    <tr>
                        <td>12:05-12:25</td>
                        <td>Long Talk: Nicole Orzan, Erman Acar, Davide Grossi, Roxana RƒÉdulescu<br><a href="papers/ALA2024_paper_15.pdf"><em>Learning in Public Goods Games with Non-Linear Utilities: a Multi-Objective Approach</em></a></td>
                    </tr>
                    <tr>
                        <td>12:30-14:00</td>
                        <td><b>Lunch Break</b><br/></td>
                    </tr>
                    <tr><td>14:00-16:00</td><td><b>Session III & Poster Session - Chair: Fan Xiaofeng</b></td></tr>
                    <tr>
                        <td>14:00-14:20</td>
                        <td>Long Talk: Zun Li, Michael Wellman<br><a href="papers/ALA2024_paper_28.pdf"><em>A Meta-Game Evaluation Framework for Deep Multiagent Reinforcement Learning</em></a></td>
                    </tr>
                    <tr>
                        <td>14:20-14:40</td>
                        <td>Long Talk: Simone Drago, Marco Mussi, Marcello Restelli, Alberto Maria Metelli<br><a href="papers/ALA2024_paper_03.pdf"><em>Intermediate Observations in Factored-Reward Bandits</em></a></td>
                    </tr>
                    <tr>
                        <td>14:40-14:55</td>
                        <td><b>Short Talks, 5 minutes each in order:</b>
                            <ul>
                                <li>Ram Rachum, Yonatan Nakar, William Tomlinson, Nitay Alon, Reuth Mirsky<br><a href="papers/ALA2024_paper_02.pdf"><em>Emergent Dominance Hierarchies in Reinforcement Learning Agents</em></a></li>
                                <li>David Milec, Ondrej Kubicek, Viliam Lis√Ω<br><a href="papers/ALA2024_paper_13.pdf"><em>Continual Depth-limited Responses for Computing Counter-strategies in Sequential Games</em></a></li>
                                <li>Rolando Fernandez, Garrett Warnell, Derrik E. Asher, Peter Stone<br><a href="papers/ALA2024_paper_14.pdf"><em>Multi-Agent Synchronization Tasks</em></a></li>
                            </ul>
                        </td>
                    </tr>
                    <tr>
                        <td>15:00-16:00</td>
                        <td><em><a href="#posterA"><b>Poster Session A</b></a></em></td>
                        <tr>
                    <tr>
                        <td>16:00-16:30</td>
                        <td><b>Coffee Break</b><br/></td>
                    </tr>
                    <tr><td>16:30-17:30</td><td><b>Session IV - Chair: Connor Yates</b></td><tr>   
                    <tr>
                        <td>16:30-17:30</td>
                        <!--<td>Invited Talk: Michael Wellman (UMichigan) <br/><em><a href="#talks2">title</a></em></td>-->
                        <td>Invited Talk: Michael Wellman <br/><em><a href="#talks2">Artificial Intelligence and its Implications for Financial Markets</a></em></td>
                    </tr>
                    <tr>
                        <td>~18:00</td>
                        <td><b>Social Gathering</b> Galbraith's Alehouse (<a href="https://maps.app.goo.gl/vv7uEwhDeDWF1VqN6">Google Maps</a>)</td>
                    </tr>
                    </table>
                    <h4>Tuesday May 7</h4>
                    <table width="100%" >
                    <tr>
                        <td>09:00-10:00</td>
                        <td><b>Session V - Chair: Connor Yates</b></td>
                    <tr>
                        <td>09:00-10:00</td>
                        <td>Invited Talk: Ann Now√© <br/><em><a href="#talks3">Centralised learning, decentralised execution. How did we get there?</a></em></td>
                    </tr>
                    <tr>
                        <td>10:00-10:45</td>
                        <td><b>Coffee Break</b><br/></td>
                    </tr>
                    <tr><td>10:45-12:30</td><td><b>Session VI - Chair: Caroline Wang</b></tr>
                    <tr>
                        <td>10:45-11:05</td>
                        <td>Long Talk: Marc Lanctot, John Schultz, Neil Burch, Max Olan Smith, Daniel Hennes, Thomas Anthony, Julien Perolat<br><a href="papers/ALA2024_paper_05.pdf"><em>Population-based Evaluation in Repeated Rock-Paper-Scissors as a Benchmark for Multiagent Reinforcement Learning</em></a></td>
                    </tr>
                    <tr>
                        <td>11:05-11:25</td>
                        <td>Long Talk: J√©r√¥me Botoko Ekila, Jens Nevens, Lara Verheyen, Katrien Beuls, Paul Van Eecke<br><a href="papers/ALA2024_paper_09.pdf"><em>Decentralised Emergence of Robust and Adaptive Linguistic Conventions in Populations of Autonomous Agents Grounded in Continuous Worlds</em></a></td>
                    </tr>
                    <tr>
                        <td>11:25-11:45</td>
                        <td>Long Talk: Alexandra Cimpean, Catholijn M Jonker, Pieter Jules Karel Libin, Ann Nowe<br><a href="papers/ALA2024_paper_22.pdf"><em>A Group And Individual Aware Framework For Fair Reinforcement Learning</em></a></td>
                    </tr>
                    <tr>
                        <td>11:45-12:05</td>
                        <td>Long Talk: Jonathan G. Faris, Conor F. Hayes, Andre R Goncalves, Kayla G. Sprenger, Daniel faissol, Brenden K. Petersen, Mikel Landajuela, Felipe Leno da Silva<br><a href="papers/ALA2024_paper_25.pdf"><em>Pareto Front Training For Multi-Objective Symbolic Optimization</em></a></td>
                    </tr>
                    <tr>
                        <td>12:05-12:25</td>
                        <td>Long Talk: J√©r√¥me Arjonilla, Tristan Cazenave and Abdallah Saffidine<br><a href="papers/ALA2024_paper_32.pdf"><em>Perfect Information Monte Carlo with postponing reasoning</em></a></td>
                    </tr>

                    <tr>
                        <td>12:30-14:00</td>
                        <td><b>Lunch Break</b><br/></td>
                    </tr>
                    <tr><td>14:00-15:45</td><td><b>Session VII & Poster Session - Chair: Gaurav Dixit</b></td></tr>
                    <tr>
                        <td>14:00-14:30</td>
                        <td><b>Short Talks, 5 minutes each in order:</b>
                            <ul>
                                <li>Kyle Crandall, Connor Yates, Corbin Wilhelmi<br><a href="papers/ALA2024_paper_04.pdf"><em>Lyapunov Guarantees for Learned Policies</em></a></li>
                                <li>Timothy Flavin, Sandip Sen<br><a href="papers/ALA2024_paper_17.pdf"><em>A Bayesian Approach to Learning Command Hierarchies for Zero-Shot Multi-Agent Coordination</em></a></li>
                                <li>Argha Boksi, Balaraman Ravindran<br><a href="papers/ALA2024_paper_16.pdf"><em>Inter-agent Transfer Learning in Communication-constrained Settings : A Student Initiated Advising Approach</em></a></li>
                                <li>Brian Burns, Aravind Sundaresan, Pedro Sequeira, Vidyasagar Sadhu<br><a href="papers/ALA2024_paper_18.pdf"><em>Learning Sensor Control for Information Gain in Dynamic, Partially Observed and Sparsely Sampled Environments</em></a></li>
                                <li>Arnau Mayoral Macau, Manel Rodriguez-Soto, Maite L√≥pez-S√°nchez, Juan Antonio Rodriguez Aguilar, Enrico Marchesini, Alessandro Farinelli<br><a href="papers/ALA2024_paper_24.pdf"><em>An approximate process for designing ethical environments with multi-agent reinforcement learning</em></a></li>
                                <li>J√©r√¥me Arjonilla, Tristan Cazenave and Abdallah Saffidine<br><a href="papers/ALA2024_paper_29.pdf"><em>Enhancing Reinforcement Learning Through Guided Search</em></a></li>
                            </ul>
                        </td>
                    </tr>
                    <tr>
                        <td>14:30-14:50</td>
                        <td>Long Talk: Radovan Halu≈°ka and Martin Schmid<br><a href="papers/ALA2024_paper_33.pdf"><em>Learning to Beat ByteRL: Exploitability of Collectible Card Game Agents</em></a></td>
                    </tr>
                    <tr>
                        <td>15:00-16:00</td>
                        <td><em><a href="#posterB"><b>Poster Session B</b></a></em></td>
                    </tr>
                    <tr>
                        <td>16:00-16:30</td>
                        <td><b>Coffee Break</b><br/></td>
                    </tr>
                    <tr>
                        <td>16:30-17:30</td>
                        <td>General Discussion<br/><em><a href="#"></a></em></td>
                    </tr>
                    <tr>
                        <td>17:30</td>
                        <td><b>Awards & Closing Remarks</b></td>
                    </tr>
                    </table>
                </div>
            </section>
            <section id="posters">
                <div id="posterA" class="container">
                    <h4>Poster Session A - Monday May 6 15:00-16:00</h4>
                    <p>All papers presented on day 1.</p>
                </div>
                <div id="posterB" class="container">
                    <h4>Poster Session B - Tuesday May 7 15:00-16:00</h4>
                    <p>All papers presented on day 2.</p>
                </div>
            </section>
            

            

        <section id="accepted">
            <div class="container">
                <h3>Accepted Papers</h3>
                <p></p>                  
            
                <table style="width:100%">
                    <tr style="text-align:center">
                        <th>Paper #</th>
                        <th>Authors</th>
                        <th>Title</th>
                    </tr>
            <tr><td>2</td><td>Ram Rachum, Yonatan Nakar, William Tomlinson, Nitay Alon, Reuth Mirsky</td><td>Emergent Dominance Hierarchies in Reinforcement Learning Agents</td></tr>
            <tr><td>3</td><td>Simone Drago, Marco Mussi, Marcello Restelli, Alberto Maria Metelli</td><td>Intermediate Observations in Factored-Reward Bandits</td></tr>
            <tr><td>4</td><td>Kyle Crandall, Connor Yates, Corbin Wilhelmi</td><td>Lyapunov Guarantees for Learned Policies</td></tr>
            <tr><td>5</td><td>Marc Lanctot, John Schultz, Neil Burch, Max Olan Smith, Daniel Hennes, Thomas Anthony, Julien Perolat</td><td>Population-based Evaluation in Repeated Rock-Paper-Scissors as a Benchmark for Multiagent Reinforcement Learning</td></tr>
            <tr><td>7</td><td>Pascal Van der Vaart, Neil Yorke-Smith, Matthijs T. J. Spaan</td><td>Bayesian Ensembles for Exploration in Deep Q-Learning</td></tr>
            <tr><td>9</td><td>J√©r√¥me Botoko Ekila, Jens Nevens, Lara Verheyen, Katrien Beuls, Paul Van Eecke</td><td>Decentralised Emergence of Robust and Adaptive Linguistic Conventions in Populations of Autonomous Agents Grounded in Continuous Worlds</td></tr>
            <tr><td>10</td><td>Hei Yi Mak, Flint Xiaofeng Fan, Luca A Lanzend√∂rfer, Cheston Tan, Wei Tsang Ooi, Roger Wattenhofer</td><td>CAESAR: Enhancing Federated RL in Heterogeneous MDPs through Convergence-Aware Sampling with Screening</td></tr>
            <tr><td>11</td><td>Sunghoon Hong, Whiyoung Jung, Deunsol Yoon, Kanghoon Lee, Woohyung Lim</td><td>Agent-Oriented Centralized Critic for Asynchronous Multi-Agent Reinforcement Learning</td></tr>
            <tr><td>13</td><td>David Milec, Ondrej Kubicek, Viliam Lis√Ω</td><td>Continual Depth-limited Responses for Computing Counter-strategies in Sequential Games</td></tr>
            <tr><td>14</td><td>Rolando Fernandez, Garrett Warnell, Derrik E. Asher, Peter Stone</td><td>Multi-Agent Synchronization Tasks</td></tr>
            <tr><td>15</td><td>Nicole Orzan, Erman Acar, Davide Grossi, Roxana RƒÉdulescu</td><td>Learning in Public Goods Games with Non-Linear Utilities: a Multi-Objective Approach</td></tr>
            <tr><td>16</td><td>Argha Boksi, Balaraman Ravindran</td><td>Inter-agent Transfer Learning in Communication-constrained Settings : A Student Initiated Advising Approach</td></tr>
            <tr><td>17</td><td>Timothy Flavin, Sandip Sen</td><td>A Bayesian Approach to Learning Command Hierarchies for Zero-Shot Multi-Agent Coordination</td></tr>
            <tr><td>18</td><td>Brian Burns, Aravind Sundaresan, Pedro Sequeira, Vidyasagar Sadhu</td><td>Learning Sensor Control for Information Gain in Dynamic, Partially Observed and Sparsely Sampled Environments</td></tr>
            <tr><td>22</td><td>Alexandra Cimpean, Catholijn M Jonker, Pieter Jules Karel Libin, Ann Nowe</td><td>A Group And Individual Aware Framework For Fair Reinforcement Learning</td></tr>
            <tr><td>23</td><td>Bram M. Renting, Holger Hoos, Catholijn M Jonker </td><td>Multi-Agent Meeting Scheduling: A Negotiation Perspective</td></tr>
            <tr><td>24</td><td>Arnau Mayoral Macau, Manel Rodriguez-Soto, Maite L√≥pez-S√°nchez, Juan Antonio Rodriguez Aguilar, Enrico Marchesini, Alessandro Farinelli</td><td>An approximate process for designing ethical environments with multi-agent reinforcement learning</td></tr>
            <tr><td>25</td><td>Jonathan G. Faris, Conor F. Hayes, Andre R Goncalves, Kayla G. Sprenger, Daniel faissol, Brenden K. Petersen, Mikel Landajuela, Felipe Leno da Silva</td><td>Pareto Front Training For Multi-Objective Symbolic Optimization</td></tr>
            <tr><td>28</td><td>Zun Li, Michael Wellman</td><td>A Meta-Game Evaluation Framework for Deep Multiagent Reinforcement Learning</td></tr>
            <tr><td>29</td><td>J√©r√¥me Arjonilla, Tristan Cazenave and Abdallah Saffidine</td><td>Enhancing Reinforcement Learning Through Guided Search</td></tr>
            <tr><td>32</td><td>J√©r√¥me Arjonilla, Tristan Cazenave and Abdallah Saffidine</td><td>Perfect Information Monte Carlo with postponing reasoning</td></tr>
            <tr><td>33</td><td>Radovan Halu≈°ka and Martin Schmid</td><td>Learning to Beat ByteRL: Exploitability of Collectible Card Game Agents</td></tr>
        </table>
    </div>
</section>



<!-- Six -->

<section id="talks">
    <div class="container">
        <h3>Invited Talks</h3>
        <h4 id='talks1'>Marc Lanctot</h4>
        <div style="width:100%;">
                <div style="width:35%; float:left;"><img src="images/marclanctot.jpg" width="90%" image-orientation="from-image"></div>
                <div style="width:65%; float:right;">
                <!--<div style="width:100%; float:right;">-->
                    <p><b>Affiliation:</b> Google Deepmind</p>
                    <!--<p><b>Website:</b> <a href="http://whirl.cs.ox.ac.uk/index.html" target="_blank">http://whirl.cs.ox.ac.uk/index.html</a></p>-->
                </div>
            </div>
            <p align="justify" class="title"><b>Title:</b> Game-Theoretic Approaches to Adaptive Learning Agents in Strategic Environments
            </p>
            <p align="justify" class="abstract"><b>Abstract:</b> In this talk, I will motivate the importance of adaptation in general environments and the role that game theory could play along the way. I will briefly talk about different ways of assessing the performance of agents that have been adopted by the community. Then, I will outline a few potential environments and evaluation schemes that could be used for such purposes. I will then talk in detail about a specific direction that embraces Meta-RL and Bayesian reasoning in a practical way, through the use of game-theoretic training regimes and applications to multiplayer games with partial observability. As a case study, I will show recent results on agents that have learned to play negotiation games through combined reinforcement learning and search, as well as observations from their interactions with human participants.
            </p>
            <!--<p align="justify" class="bio"><b>Bio:</b> text here.
            </p>-->
            <p class="entry-footer"></p>

            <h4 id='talks2'>Michael Wellman</h4>
            <div style="width:100%;">
                <div style="width:35%; float:left;"><img src="images/michaelwellman.jpg" width="90%" image-orientation="from-image"></div>
                <div style="width:65%; float:right;">
                <!--<div style="width:100%; float:right;">-->
                    <p><b>Affiliation:</b> University of Michigan</p>
                    <p><b>Website:</b> <a href="https://strategicreasoning.org/michael-p-wellman/" target="_blank">https://strategicreasoning.org/michael-p-wellman/</a></p>
                </div>
            </div>
            <p align="justify" class="title"><b>Title:</b> Artificial Intelligence and its Implications for Financial Markets
            </p>
            <p align="justify" class="abstract"><b>Abstract:</b> The rapid advancement of surprisingly capable AI is raising questions about AI‚Äôs impact on virtually all aspects of our economy and society. The nexus of AI and Finance is especially salient, building on the impact AI has already had on trading and other financial domains. New AI developments could exacerbate market manipulation, and otherwise create loopholes in regulatory regimes. We need improved ways to anticipate AI impacts and evaluate capabilities of advanced interactive AI. 
            </p>
                <p align="justify" class="bio"><b>Bio:</b> Michael P. Wellman is Professor and Division Chair of Computer Science & Engineering at the University of Michigan. He received a PhD from the Massachusetts Institute of Technology in 1988 for his work in qualitative probabilistic reasoning and decision-theoretic planning. From 1988 to 1992, Wellman conducted research in these areas at the USAF‚Äôs Wright Laboratory. For the past 30 years, his research has focused on computational market mechanisms and game-theoretic reasoning methods, with applications in electronic commerce, finance, and cyber-security. As Chief Market Technologist for TradingDynamics, Inc., he designed configurable auction technology for dynamic business-to-business commerce. Wellman previously served as Chair of the ACM Special Interest Group on Electronic Commerce (SIGecom), and as Executive Editor of the Journal of Artificial Intelligence Research. He is a Fellow of the Association for the Advancement of Artificial Intelligence and the Association for Computing Machinery. </p>
                <p class="entry-footer"></p>              
                
                
            <h4 id='talks3'>Ann Now√©</h4>
                <div style="width:100%;">
                    <div style="width:35%; float:left;"><img src="images/annnowe.jpg" width="90%" image-orientation="from-image"></div>
                <div style="width:65%; float:right;">
                    <p><b>Affiliation:</b>Vrije Universiteit Brussel</p>
                    <!--<p><b>Website:</b> <a href="https://www.ccs.neu.edu/home/camato/index.html" target="_blank">https://www.ccs.neu.edu/home/camato/index.html</a></p>-->
                </div>
                </div>
                    <p class="title" align="justify"><b>Title: Centralised learning, decentralised execution. How did we get there?</b></p>
                    <!--<p class="abstract" align="justify"><b>Abstract: </b>The decreasing cost and increasing sophistication of hardware has created new opportunities for applications where teams of agents (e.g., robots, autonomous vehicles, AI software) can be deployed to solve complex problems. However, if such systems are to become widely deployable, we must develop the control and coordination methods that allow the agents to perform well in large real-world domains with significant uncertainty and communication limitations. I‚Äôll first talk about some of the fundamental challenges and misunderstandings of multi-agent reinforcement learning along with promising future directions. In particular, I‚Äôll discuss how 1) centralized critics are not strictly better than decentralized critics (and can be worse), and 2) state-based critics are unsound and work well only on a subclass of problems. I‚Äôll also talk about some of our work on scalable reinforcement learning methods for asynchronous multi-agent systems. </p>-->
                    
                    <p align="justify" class="bio"><b>Bio: </b>Ann Now√© graduated from the University of Ghent in 1987, where she studied mathematics with optional courses in computer science. She then became research assistant at the University of Brussels where she finished her PhD in 1994 in collaboration with Queen Mary and Westfield College, University of London. The subject of her PhD is located in the intersection of Computer Science (A.I.), Control Theory (Fuzzy Control) and Mathematics (Numerical Analysis, Stochastic Approximation). After a period of 3 years as senior research assistant at the VUB, she became a Postdoctoral Fellow of the Fund for Scientific Research-Flanders (F.W.O.). Nowadays, She is a professor both in the Computer Science Department of the faculty of Sciences as in the Computer Science group of the Engineering Faculty.</p>
                    <p class="entry-footer"></p>        
                </div>
            </section>


            <!-- Six -->
            <!--

                <section id="awards">
                    <div class="container">
                        <h3>Awards</h3>
                        
                        <h4 id='bestpaperaward'>Best Paper Award</h4>
            -->
                        <!--<p align="justify" class="title"><b></b> Sponsored by Neural Computing & Applications</a></p>-->
                        <!--<p>We are pleased to announce the best paper of ALA 2023, sponsored by Neural Computing & Applications, is Fair Deep Reinforcement Learning with Generalized Gini Welfare Functions, by Guanbao Yu, Umer Siddique and Paul Weng!</p>-->
                    
                    
                    <!--
                        <h4 id='visionarypaperaward'>Visionary Paper Award</h4>
                        
                    <table style="width:100%">
                        <tr><td>32</td><td> Conor F. Hayes, Diederik M. Roijers, Enda Howley and Patrick Mannion</td><td><em><a target='_blank' href='papers/ALA2022_paper_32.pdf'> Multi-Objective Distributional Value Iteration</a></td><td><em><a target='_blank' href='https://youtu.be/BqqX1U0Njxg'> [video]</a></em></td></tr>
                    </table>

                    <h4 id='cogmentchallengewinner'>Cogment Challenge Winners</h4>
                    <p align="justify" class="title"><b></b> Sponsored by AI Redefined</a></p>                    
                    <table style="width:100%">
                        <tr><td>36</td><td> Chaitanya Kharyal, Tanmay Sinha and Matthew Taylor</td><td><em><a target='_blank' href='papers/ALA2022_paper_36.pdf'> Work-in-Progress: Multi-Teacher Curriculum Design for Sparse Reward Environments</a></td><td><em><a target='_blank' href='https://youtu.be/v__MJvfjiBw'> [video]</a></em></td></tr>
                        <tr><td>5</td><td>Benjamin Wexler, Elad Sarafian and Sarit Kraus</td><td><em><a target='_blank' href='papers/ALA2022_paper_5.pdf'> Analyzing and Overcoming Degradation in Warm-Start Off-Policy Reinforcement Learning</a></td><td><em><a target='_blank' href='https://youtu.be/_cveeScjMlY'> [video]</a></em></td></tr>
                    </table>
                    <p class="entry-footer"></p>                   
                    -->
        <!--
                </div>
            </section>
        -->
            
            
            <!-- Seven -->
                <section id="pc">
                    <div class="container">
                        <h3>Programe Committee</h3>         
                        
                        <ul>
                            <li>Adrian Agogino, University of Texas, Austin, USA</li>
                            <li>Lucas Nunes Alegre, Federal University of Rio Grande do Sul, BRA</li>
                            <li>Hicham Azmani, Vrije Universiteit Brussel, BEL</li>
                            <li>Alexandra Cimpean, Vrije Universiteit Brussel, BEL</li>
                            <li>Valentin Colliard, LIP6, FRA</li>
                            <li>Elena Congeduti, Delft University of Technology, NLD</li>
                            <li>Kyle Crandall, US Naval Research Lab, USA</li>
                            <li>Jiaxun Cui, The University of Texas at Austin, USA</li>
                            <li>Ryan D'Orazio, Universit√© de Montr√©al , CAN</li>
                            <li>Gaurav Dixit, Oregon State University, USA</li>
                            <li>Simone Drago, Polytechnic Institute of Milan, ITA</li>
                            <li>Ishan Durugkar, Sony AI Inc., USA</li>
                            <li>J√©r√¥me Botoko Ekila, Vrije Universiteit Brussel, BEL</li>
                            <li>Flint Xiaofeng Fan, National University of Singapore, SGP</li>
                            <li>Jonathan G. Faris, University of Colorado at Boulder, USA</li>
                            <li>Florian Felten, University of Luxemburg, LUX</li>
                            <li>Rolando Fernandez, University of Texas at Austin, USA</li>
                            <li>Timothy Flavin, University of Tulsa, USA</li>
                            <li>Tim French, University of Western Australia, AUS</li>
                            <li>Julian Garcia, Monash University, AUS</li>
                            <li>Conor F. Hayes, Lawrence Livermore National Labs, USA</li>
                            <li>Whiyoung Jung, LG AI Research, KOR</li>
                            <li>Thommen Karimpanal George, Deakin University, AUS</li>
                            <li>Sammie Katt, Aalto University, FIN</li>
                            <li>Ond≈ôej Kub√≠ƒçek, Czech Technical University , CZE</li>
                            <li>Marc Lanctot, Google DeepMind, CAN</li>
                            <li>Pieter  Libin, Vrije Universiteit Brussel, BEL</li>
                            <li>Chuang-Chieh Lin, Tamkang University, TPE</li>
                            <li>Viliam Lis√Ω , Czech Technical University in Prague, CZE</li>
                            <li>Robert Loftin, University of Sheffield, GBR</li>
                            <li>Junlin Lu, National University of Ireland, Galway, IRL</li>
                            <li>Simon Lucas, Queen Mary University of London , GBR</li>
                            <li>Patrick MacAlpine, Sony AI, USA</li>
                            <li>Karl Mason, University of Galway, IRL</li>
                            <li>Stephanie  Milani, Carnegie Mellon University , USA</li>
                            <li>David Milec, Czech Technical University in Prague, CZE</li>
                            <li>Nicole Orzan, University of Groningen, NLD</li>
                            <li>Bei Peng, University of Liverpool, GBR</li>
                            <li>Diego Perez Liebana , Queen Mary University of London , GBR</li>
                            <li>Gang  Qiao, Siemens Healthineers, USA</li>
                            <li>Ram Rachum, Bar-Ilan University, ISR</li>
                            <li>Roxana RƒÉdulescu, Vrije Universiteit Brussel, BEL</li>
                            <li>Arrasy Rahman, University of Texas at Austin, USA</li>
                            <li>Balaraman Ravindran, Indian Institute of Technology Madras, IND</li>
                            <li>Bram M. Renting, Leiden University, NLD</li>
                            <li>Mathieu Reymond, Vrije Universiteit Brussel, BEL</li>
                            <li>Manel Rodriguez-Soto, Artificial Intelligence Research Institute, Spanish National Research Council, ESP</li>
                            <li>Diederik Roijers, University of Amsterdam, NLD</li>
                            <li>Willem R√∂pke, Vrije Universiteit Brussel, BEL</li>
                            <li>Andries Rosseau, Vrije Universiteit Brussel, BEL</li>
                            <li>Sam  Sokota, Carnegie Mellon University , USA</li>
                            <li>Michal  Sustr, AIC FEE CTU , CZE</li>
                            <li>Paolo Turrini, University of Warwick, GBR</li>
                            <li>Peter Vamplew, Federation University Australia, AUS</li>
                            <li>Pascal Van der Vaart, Delft University of Technology, NLD</li>
                            <li>Timothy Verstraeten, Vrije Universiteit Brussel, BEL</li>
                            <li>Brian Zhang, Carnegie Mellon University , USA</li>
                            <li>Weiye Zhao, Carnegie Mellon University , USA</li>
                            <li>Junpei Zhong, Hong Kong Polytechnic University, HK</li>
                        </ul>

                    </div>
                </section>
            

            
                <!-- eight -->
                <section id="organization">
                    <div class="container">
                        <h3>Organization</h3>
                        This year's workshop is organised by:
                        <ul>
                        <li><a href="https://avalos.fr" target="_blank">Raphael Avalos</a> (Vrije Universiteit Brussel, BE) </li>
                        <li>David Milec (Czech Technical University in Prague, CZ) </li>
                        <li>Henrik M&uuml;ller (Leibniz University Hannover, DE) </li>
                        <li><a href="https://carolinewang01.github.io" target="_blank">Caroline Wang</a> (University of Texas at Austin, US) </li>
                        <li><a href="https://yatesco.org" target="_blank">Connor Yates</a> (U.S. Naval Research Laboratory, US)</li>
                    </ul>
                    
                    Senior Steering Committee Members:
                    <ul>
                        <li>Enda Howley (University of Galway, IE)</li>
                        <li>Daniel Kudenko (University of York, UK)</li>
                        <li>Patrick Mannion (University of Galway, IE)</li>
                        <li>Ann Now&eacute; (Vrije Universiteit Brussel, BE)</li>
                        <li>Sandip Sen (University of Tulsa, US)</li>
                        <li>Peter Stone (University of Texas at Austin, US)</li>
                        <li>Matthew Taylor (University of Alberta, CA)</li>
                        <li>Kagan Tumer (Oregon State University, US)</li>
                        <li>Karl Tuyls (University of Liverpool, UK)</li>
                    </ul>
                </div>
            </section>
            
            
            
            <!--
            <section id="sponsor">
                <div class="container">
                    <h3>Sponsorship</h3>
                    <p align="justify">The ALA 2022 Best Paper Award is kindly sponsored by the Springer journal <a href="https://www.springer.com/computer/ai/journal/521" target="_blank"> Neural Computing and Applications</a>.</p>
                    <a href="https://www.springer.com/computer/ai/journal/521" target='_blank'><img src='images/nca.jpg' height='200px' alt='NCA' /></a>
                </div>
            </section>

            <section id="ai_ethics">
                <div class="container">
                    <h3>Trustworthy Adaptive and Learning Agents</h3>
                    <p align="justify">Authors and attendees of ALA 2022 who are interested in trustworthiness in agent-based systems are invited to submit their work to a topical collection (TC) on Trustworthy Adaptive and Learning Agents (TALA).
                    This TC solicits original research articles, reviews/surveys, and opinion pieces/commentaries relating to trustworthiness in agent-based systems, including those that employ learning and/or adaptation.
                    The TALA TC has an open call for papers; it is not necessary to submit preliminary work to the ALA workshop in order to have your manuscript considered for publication in this TC.</p>
                    <p align="justify"><a href="https://www.springer.com/journal/43681/updates/19318686" target="_blank"> AI and Ethics</a></p>
                    <a href="https://www.springer.com/computer/ai/journal/521" target='_blank'><img src='images/ai_ethics.jpg' height='200px' alt='NCA' /></a>
                </div>
            </section>
            -->
            
            <!-- ten -->
            <section id="contact">
                <div class="container">
                    <h3>Contact</h3>
                    <p align="justify">If you have any questions about the ALA workshop, please contact the organizers at: <br/>
                    ala.workshop.2024 AT gmail.com
                    </p>
                    <p> For more general news, discussion, collaboration and networking opportunities with others interested in Adaptive Learning Agents then please join our Linkedin Group
                    <a class="fa" href="https://www.linkedin.com/groups/4412140/" >
                        <i class="fa fa-linkedin"></i>
                    </a> </p>
                </div>
            </section>
        
        <!-- Footer -->
        <section id="footer">
            <div class="container">
                <ul class="copyright">
                    <li>&copy; Adaptive Learning Agents Workshop 2024. All rights reserved.</li>
                    <li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
                    <li>Icons made by <a href="https://www.flaticon.com/authors/freepik" title="Freepik">Freepik</a> from <a href="https://www.flaticon.com/" title="Flaticon">www.flaticon.com</a> are licensed by <a href="http://creativecommons.org/licenses/by/3.0/" title="Creative Commons BY 3.0" target="_blank">CC 3.0 BY</a></li>
                    <!--<li>Header image by <a href="https://commons.wikimedia.org/wiki/File:Big_Ben_at_sunset_-_2014-10-27_17-30.jpg">Colin¬†from¬†Wikimedia Commons</a>, licensed under <a href="https://creativecommons.org/licenses/by-sa/4.0/" title="Creative Commons BY-SA 4.0" target="_blank">CC BY-SA 4.0</a></li>-->
                    <li>Header image by <a href="https://commons.wikimedia.org/wiki/File:Auckland_Skyline_as_seen_from_Devonport_20100128_3.jpg">DXR</a>, licensed under <a href="https://creativecommons.org/licenses/by-sa/4.0" title="Creative Commons BY-SA 4.0" target="_blank">CC BY-SA 4.0</a>, via Wikimedia Commons</li>
                </ul>
            </div>
        </section>
        
        </div>
        
        <!-- Scripts -->
        <script src="assets/js/jquery.min.js"></script>
        <script src="assets/js/jquery.scrollex.min.js"></script>
        <script src="assets/js/jquery.scrolly.min.js"></script>
        <script src="assets/js/browser.min.js"></script>
        <script src="assets/js/breakpoints.min.js"></script>
        <script src="assets/js/util.js"></script>
        <script src="assets/js/main.js"></script>
        
    </body>
</html>
